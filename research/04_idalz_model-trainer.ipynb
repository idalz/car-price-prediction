{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\DataScienceProjects\\\\car-price-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    processed_dataset_dir: Path\n",
    "    embed_dim_file_path: str\n",
    "    num_dim_file_path: str\n",
    "    model_dir: Path\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "    lr: float\n",
    "    layers: List\n",
    "    dropout: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Manager\n",
    "from carPricePrediction.constants import *\n",
    "from carPricePrediction.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self)-> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([\n",
    "            config.root_dir, \n",
    "            config.model_dir\n",
    "        ])\n",
    "\n",
    "        data_transformation_config = ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            processed_dataset_dir = config.processed_dataset_dir,\n",
    "            embed_dim_file_path = config.embed_dim_file_path,\n",
    "            num_dim_file_path = config.num_dim_file_path,\n",
    "            model_dir = config.model_dir,\n",
    "            batch_size = params.batch_size,\n",
    "            epochs = params.epochs,\n",
    "            lr = params.lr,\n",
    "            layers = params.layers,\n",
    "            dropout = params.dropout       \n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, n_cont, out_dim, layers, dout=0.5):\n",
    "        super().__init__()\n",
    "        # Create embedding layer\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(inp, out) for inp,out in embedding_dim])\n",
    "        # Apply dropout (prevent overfitting)\n",
    "        self.emb_drop = nn.Dropout(dout)\n",
    "        # Apply batch normalization to numerical features\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        # Total dimension of embedding layers\n",
    "        n_emb = sum((out for inp,out in embedding_dim))\n",
    "        # Total input (embedding and continuous) \n",
    "        n_inp = n_emb + n_cont\n",
    "\n",
    "        layerlist = []\n",
    "        for i in layers:\n",
    "            # Create Linear layer\n",
    "            layerlist.append(nn.Linear(n_inp,i))\n",
    "            # Add activation function\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            # Add batch normalization in the neurons\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            # Drop some neurons\n",
    "            layerlist.append(nn.Dropout(dout))\n",
    "            # The input for the next layer\n",
    "            n_inp = i\n",
    "        # Final layer - output layer\n",
    "        layerlist.append(nn.Linear(layers[-1], out_dim))\n",
    "\n",
    "        # Wrap the layers with Sequential\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self, x_cat, x_cont): \n",
    "        # Create and concat embeddings\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x_cat = torch.cat(embeddings, 1)\n",
    "        # Dropout\n",
    "        x_cat = self.emb_drop(x_cat)\n",
    "        # Batch normalization\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        # Concat all features\n",
    "        x = torch.cat([x_cat, x_cont], 1)\n",
    "        # Return layer with input x\n",
    "        layer = self.layers(x)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from carPricePrediction.components.feed_forward_nn import FeedForwardNN\n",
    "from carPricePrediction.entity import ModelTrainerConfig\n",
    "from carPricePrediction.logging.model_logger import ModelLogger\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_shuffled_batches(self, train_data, val_data, batch_size):\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "        return train_loader, val_loader\n",
    "\n",
    "    def train(self):\n",
    "        # Choose device\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Load train and validation data\n",
    "        train_filepath = os.path.join(self.config.processed_dataset_dir, \"train.pth\")\n",
    "        train_data = torch.load(train_filepath)\n",
    "\n",
    "        val_filepath = os.path.join(self.config.processed_dataset_dir, \"val.pth\")\n",
    "        val_data = torch.load(val_filepath)\n",
    "\n",
    "        # Load dimensions\n",
    "        with open(self.config.num_dim_file_path, 'rb') as f:\n",
    "            num_dim = pickle.load(f)\n",
    "\n",
    "        with open(self.config.embed_dim_file_path, 'rb') as f:\n",
    "            embedding_dim = pickle.load(f)\n",
    "        \n",
    "        # Set batches\n",
    "        batch_size = self.config.batch_size\n",
    "        train_loader, val_loader = self.get_shuffled_batches(train_data, val_data, batch_size)\n",
    "        \n",
    "        # Create model\n",
    "        torch.manual_seed(100)\n",
    "        model = FeedForwardNN(\n",
    "            embedding_dim=embedding_dim, \n",
    "            n_cont=num_dim, \n",
    "            out_dim=1, \n",
    "            layers=self.config.layers, \n",
    "            dout=self.config.dropout\n",
    "        ).to(device)\n",
    "\n",
    "        # Choose loss funciton and optimizer\n",
    "        loss_function = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.lr)\n",
    "\n",
    "        # Create the model logger\n",
    "        model_logger_file_path = os.path.join(self.config.model_dir, 'trainfile.log')\n",
    "        modelLogger = ModelLogger(model_logger_file_path)\n",
    "\n",
    "        # Set epochs\n",
    "        num_epochs = self.config.epochs \n",
    "\n",
    "        # Train model\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for batch_idx, (cat_data, num_data, target) in enumerate(train_loader):\n",
    "                cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(cat_data, num_data)\n",
    "                loss = torch.sqrt(loss_function(prediction, target))\n",
    "                total_loss += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss /= len(train_loader)\n",
    "            \n",
    "            # Get validation loss\n",
    "            val_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for cat_data, num_data, target in val_loader:\n",
    "                    cat_data, num_data, target = cat_data.to(device), num_data.to(device), target.to(device)\n",
    "                    prediction = model(cat_data, num_data)\n",
    "                    val_loss += torch.sqrt(loss_function(prediction, target))\n",
    "                val_loss /= len(val_loader)\n",
    "\n",
    "            # Add to log file\n",
    "            message = f'Epoch {epoch+1}/{num_epochs}, train_Loss: {total_loss}, val_Loss: {val_loss:.4f}'\n",
    "            modelLogger.log_message(message)\n",
    "\n",
    "        # Save the entire model\n",
    "        model_file_path = os.path.join(self.config.model_dir, 'model.pth')\n",
    "        torch.save(model, model_file_path)\n",
    "\n",
    "        # Save model's state\n",
    "        model_state_file_path = os.path.join(self.config.model_dir, 'model_state_dict.pth')\n",
    "        torch.save(model.state_dict(), model_state_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-30 21:32:10,710: INFO: common: yaml file: config\\config.yaml loaded successfully.]\n",
      "[2024-03-30 21:32:10,715: INFO: common: yaml file: params.yaml loaded successfully.]\n",
      "[2024-03-30 21:32:10,716: INFO: common: Created directory at: artifacts]\n",
      "[2024-03-30 21:32:10,717: INFO: common: Created directory at: artifacts/model]\n",
      "[2024-03-30 21:32:10,718: INFO: common: Created directory at: artifacts/model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idale\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-30 21:32:12,654: INFO: model_logger: Epoch 1/1000, train_Loss: 23704.708984375, val_Loss: 22507.0215]\n",
      "[2024-03-30 21:32:12,856: INFO: model_logger: Epoch 2/1000, train_Loss: 23727.341796875, val_Loss: 22823.5742]\n",
      "[2024-03-30 21:32:13,122: INFO: model_logger: Epoch 3/1000, train_Loss: 23681.849609375, val_Loss: 22600.8438]\n",
      "[2024-03-30 21:32:13,321: INFO: model_logger: Epoch 4/1000, train_Loss: 23628.64453125, val_Loss: 22989.1367]\n",
      "[2024-03-30 21:32:13,532: INFO: model_logger: Epoch 5/1000, train_Loss: 23704.0859375, val_Loss: 22714.9258]\n",
      "[2024-03-30 21:32:13,844: INFO: model_logger: Epoch 6/1000, train_Loss: 23686.6796875, val_Loss: 23056.9258]\n",
      "[2024-03-30 21:32:14,122: INFO: model_logger: Epoch 7/1000, train_Loss: 23609.1171875, val_Loss: 23187.7031]\n",
      "[2024-03-30 21:32:14,357: INFO: model_logger: Epoch 8/1000, train_Loss: 23608.158203125, val_Loss: 22469.8105]\n",
      "[2024-03-30 21:32:14,579: INFO: model_logger: Epoch 9/1000, train_Loss: 23607.236328125, val_Loss: 22583.6367]\n",
      "[2024-03-30 21:32:14,861: INFO: model_logger: Epoch 10/1000, train_Loss: 23487.646484375, val_Loss: 22762.6719]\n",
      "[2024-03-30 21:32:15,072: INFO: model_logger: Epoch 11/1000, train_Loss: 23485.08203125, val_Loss: 22599.2188]\n",
      "[2024-03-30 21:32:15,275: INFO: model_logger: Epoch 12/1000, train_Loss: 23480.763671875, val_Loss: 22695.2695]\n",
      "[2024-03-30 21:32:15,545: INFO: model_logger: Epoch 13/1000, train_Loss: 23390.88671875, val_Loss: 22546.9414]\n",
      "[2024-03-30 21:32:15,755: INFO: model_logger: Epoch 14/1000, train_Loss: 23275.9609375, val_Loss: 22335.0000]\n",
      "[2024-03-30 21:32:15,962: INFO: model_logger: Epoch 15/1000, train_Loss: 23194.234375, val_Loss: 22430.9902]\n",
      "[2024-03-30 21:32:16,312: INFO: model_logger: Epoch 16/1000, train_Loss: 23186.765625, val_Loss: 22155.7793]\n",
      "[2024-03-30 21:32:16,524: INFO: model_logger: Epoch 17/1000, train_Loss: 23054.583984375, val_Loss: 22661.3438]\n",
      "[2024-03-30 21:32:16,739: INFO: model_logger: Epoch 18/1000, train_Loss: 23002.06640625, val_Loss: 21872.5195]\n",
      "[2024-03-30 21:32:16,956: INFO: model_logger: Epoch 19/1000, train_Loss: 22900.59765625, val_Loss: 20946.0664]\n",
      "[2024-03-30 21:32:17,256: INFO: model_logger: Epoch 20/1000, train_Loss: 22799.994140625, val_Loss: 21676.5820]\n",
      "[2024-03-30 21:32:17,478: INFO: model_logger: Epoch 21/1000, train_Loss: 22676.2109375, val_Loss: 22054.5215]\n",
      "[2024-03-30 21:32:17,696: INFO: model_logger: Epoch 22/1000, train_Loss: 22507.478515625, val_Loss: 21940.8418]\n",
      "[2024-03-30 21:32:18,015: INFO: model_logger: Epoch 23/1000, train_Loss: 22556.576171875, val_Loss: 21588.7969]\n",
      "[2024-03-30 21:32:18,223: INFO: model_logger: Epoch 24/1000, train_Loss: 22342.515625, val_Loss: 21335.4727]\n",
      "[2024-03-30 21:32:18,426: INFO: model_logger: Epoch 25/1000, train_Loss: 22281.552734375, val_Loss: 21175.1465]\n",
      "[2024-03-30 21:32:18,700: INFO: model_logger: Epoch 26/1000, train_Loss: 22181.255859375, val_Loss: 20993.9805]\n",
      "[2024-03-30 21:32:18,927: INFO: model_logger: Epoch 27/1000, train_Loss: 22034.31640625, val_Loss: 20904.2910]\n",
      "[2024-03-30 21:32:19,157: INFO: model_logger: Epoch 28/1000, train_Loss: 21891.50390625, val_Loss: 20038.0156]\n",
      "[2024-03-30 21:32:19,433: INFO: model_logger: Epoch 29/1000, train_Loss: 21763.923828125, val_Loss: 20492.5664]\n",
      "[2024-03-30 21:32:19,661: INFO: model_logger: Epoch 30/1000, train_Loss: 21591.197265625, val_Loss: 20320.2344]\n",
      "[2024-03-30 21:32:19,890: INFO: model_logger: Epoch 31/1000, train_Loss: 21388.146484375, val_Loss: 20817.1465]\n",
      "[2024-03-30 21:32:20,129: INFO: model_logger: Epoch 32/1000, train_Loss: 21235.87890625, val_Loss: 20462.4414]\n",
      "[2024-03-30 21:32:20,441: INFO: model_logger: Epoch 33/1000, train_Loss: 21087.501953125, val_Loss: 19610.0879]\n",
      "[2024-03-30 21:32:20,659: INFO: model_logger: Epoch 34/1000, train_Loss: 20993.6640625, val_Loss: 19959.8008]\n",
      "[2024-03-30 21:32:20,872: INFO: model_logger: Epoch 35/1000, train_Loss: 20819.578125, val_Loss: 19633.0527]\n",
      "[2024-03-30 21:32:21,140: INFO: model_logger: Epoch 36/1000, train_Loss: 20613.12890625, val_Loss: 20016.7891]\n",
      "[2024-03-30 21:32:21,348: INFO: model_logger: Epoch 37/1000, train_Loss: 20440.779296875, val_Loss: 19143.6328]\n",
      "[2024-03-30 21:32:21,550: INFO: model_logger: Epoch 38/1000, train_Loss: 20191.953125, val_Loss: 19782.3867]\n",
      "[2024-03-30 21:32:21,825: INFO: model_logger: Epoch 39/1000, train_Loss: 20017.341796875, val_Loss: 19385.4316]\n",
      "[2024-03-30 21:32:22,020: INFO: model_logger: Epoch 40/1000, train_Loss: 19820.6875, val_Loss: 19444.2402]\n",
      "[2024-03-30 21:32:22,223: INFO: model_logger: Epoch 41/1000, train_Loss: 19607.009765625, val_Loss: 18675.4238]\n",
      "[2024-03-30 21:32:22,426: INFO: model_logger: Epoch 42/1000, train_Loss: 19491.654296875, val_Loss: 18063.3711]\n",
      "[2024-03-30 21:32:22,699: INFO: model_logger: Epoch 43/1000, train_Loss: 19346.951171875, val_Loss: 18455.7207]\n",
      "[2024-03-30 21:32:22,906: INFO: model_logger: Epoch 44/1000, train_Loss: 18980.158203125, val_Loss: 17834.5293]\n",
      "[2024-03-30 21:32:23,135: INFO: model_logger: Epoch 45/1000, train_Loss: 18823.822265625, val_Loss: 18690.6836]\n",
      "[2024-03-30 21:32:23,436: INFO: model_logger: Epoch 46/1000, train_Loss: 18684.30078125, val_Loss: 18167.6914]\n",
      "[2024-03-30 21:32:23,653: INFO: model_logger: Epoch 47/1000, train_Loss: 18431.015625, val_Loss: 17470.5684]\n",
      "[2024-03-30 21:32:23,869: INFO: model_logger: Epoch 48/1000, train_Loss: 18177.60546875, val_Loss: 17508.0742]\n",
      "[2024-03-30 21:32:24,154: INFO: model_logger: Epoch 49/1000, train_Loss: 17925.064453125, val_Loss: 16807.2656]\n",
      "[2024-03-30 21:32:24,372: INFO: model_logger: Epoch 50/1000, train_Loss: 17727.1875, val_Loss: 16752.7012]\n",
      "[2024-03-30 21:32:24,591: INFO: model_logger: Epoch 51/1000, train_Loss: 17492.53125, val_Loss: 17198.2656]\n",
      "[2024-03-30 21:32:24,873: INFO: model_logger: Epoch 52/1000, train_Loss: 17325.26171875, val_Loss: 16439.6777]\n",
      "[2024-03-30 21:32:25,086: INFO: model_logger: Epoch 53/1000, train_Loss: 17057.875, val_Loss: 16504.1699]\n",
      "[2024-03-30 21:32:25,292: INFO: model_logger: Epoch 54/1000, train_Loss: 16799.65625, val_Loss: 15455.8633]\n",
      "[2024-03-30 21:32:25,524: INFO: model_logger: Epoch 55/1000, train_Loss: 16585.55078125, val_Loss: 15981.6328]\n",
      "[2024-03-30 21:32:25,851: INFO: model_logger: Epoch 56/1000, train_Loss: 16345.591796875, val_Loss: 15871.0068]\n",
      "[2024-03-30 21:32:26,077: INFO: model_logger: Epoch 57/1000, train_Loss: 16176.3115234375, val_Loss: 14947.5547]\n",
      "[2024-03-30 21:32:26,317: INFO: model_logger: Epoch 58/1000, train_Loss: 15880.517578125, val_Loss: 14987.8574]\n",
      "[2024-03-30 21:32:26,684: INFO: model_logger: Epoch 59/1000, train_Loss: 15633.1435546875, val_Loss: 14833.1475]\n",
      "[2024-03-30 21:32:26,930: INFO: model_logger: Epoch 60/1000, train_Loss: 15418.568359375, val_Loss: 14181.1484]\n",
      "[2024-03-30 21:32:27,226: INFO: model_logger: Epoch 61/1000, train_Loss: 15126.7578125, val_Loss: 14672.9922]\n",
      "[2024-03-30 21:32:27,536: INFO: model_logger: Epoch 62/1000, train_Loss: 14966.818359375, val_Loss: 14363.9473]\n",
      "[2024-03-30 21:32:27,772: INFO: model_logger: Epoch 63/1000, train_Loss: 14685.5810546875, val_Loss: 14784.8701]\n",
      "[2024-03-30 21:32:27,989: INFO: model_logger: Epoch 64/1000, train_Loss: 14491.7294921875, val_Loss: 13193.6816]\n",
      "[2024-03-30 21:32:28,195: INFO: model_logger: Epoch 65/1000, train_Loss: 14179.77734375, val_Loss: 13625.6709]\n",
      "[2024-03-30 21:32:28,476: INFO: model_logger: Epoch 66/1000, train_Loss: 13962.5419921875, val_Loss: 13390.5420]\n",
      "[2024-03-30 21:32:28,704: INFO: model_logger: Epoch 67/1000, train_Loss: 13704.615234375, val_Loss: 12503.7461]\n",
      "[2024-03-30 21:32:28,967: INFO: model_logger: Epoch 68/1000, train_Loss: 13453.7734375, val_Loss: 12860.6074]\n",
      "[2024-03-30 21:32:29,316: INFO: model_logger: Epoch 69/1000, train_Loss: 13241.8212890625, val_Loss: 13010.6426]\n",
      "[2024-03-30 21:32:29,547: INFO: model_logger: Epoch 70/1000, train_Loss: 13169.3623046875, val_Loss: 12791.4121]\n",
      "[2024-03-30 21:32:29,854: INFO: model_logger: Epoch 71/1000, train_Loss: 12864.8701171875, val_Loss: 12363.0586]\n",
      "[2024-03-30 21:32:30,148: INFO: model_logger: Epoch 72/1000, train_Loss: 12522.3779296875, val_Loss: 11907.9355]\n",
      "[2024-03-30 21:32:30,370: INFO: model_logger: Epoch 73/1000, train_Loss: 12439.87109375, val_Loss: 12197.1523]\n",
      "[2024-03-30 21:32:30,599: INFO: model_logger: Epoch 74/1000, train_Loss: 12161.880859375, val_Loss: 11709.9287]\n",
      "[2024-03-30 21:32:30,875: INFO: model_logger: Epoch 75/1000, train_Loss: 12018.5869140625, val_Loss: 10785.2764]\n",
      "[2024-03-30 21:32:31,072: INFO: model_logger: Epoch 76/1000, train_Loss: 11798.6279296875, val_Loss: 11484.8164]\n",
      "[2024-03-30 21:32:31,273: INFO: model_logger: Epoch 77/1000, train_Loss: 11698.5341796875, val_Loss: 10352.1934]\n",
      "[2024-03-30 21:32:31,480: INFO: model_logger: Epoch 78/1000, train_Loss: 11441.0283203125, val_Loss: 11463.7256]\n",
      "[2024-03-30 21:32:31,740: INFO: model_logger: Epoch 79/1000, train_Loss: 11124.5888671875, val_Loss: 10817.3594]\n",
      "[2024-03-30 21:32:31,941: INFO: model_logger: Epoch 80/1000, train_Loss: 11003.59375, val_Loss: 10748.3477]\n",
      "[2024-03-30 21:32:32,147: INFO: model_logger: Epoch 81/1000, train_Loss: 10809.142578125, val_Loss: 10720.5527]\n",
      "[2024-03-30 21:32:32,405: INFO: model_logger: Epoch 82/1000, train_Loss: 10596.8681640625, val_Loss: 9900.8740]\n",
      "[2024-03-30 21:32:32,610: INFO: model_logger: Epoch 83/1000, train_Loss: 10512.3310546875, val_Loss: 10356.5752]\n",
      "[2024-03-30 21:32:32,815: INFO: model_logger: Epoch 84/1000, train_Loss: 10406.55078125, val_Loss: 9890.3154]\n",
      "[2024-03-30 21:32:33,093: INFO: model_logger: Epoch 85/1000, train_Loss: 10213.4921875, val_Loss: 9111.9668]\n",
      "[2024-03-30 21:32:33,289: INFO: model_logger: Epoch 86/1000, train_Loss: 10023.49609375, val_Loss: 10385.9131]\n",
      "[2024-03-30 21:32:33,493: INFO: model_logger: Epoch 87/1000, train_Loss: 9995.07421875, val_Loss: 9819.8027]\n",
      "[2024-03-30 21:32:33,692: INFO: model_logger: Epoch 88/1000, train_Loss: 9863.4375, val_Loss: 9733.9414]\n",
      "[2024-03-30 21:32:33,971: INFO: model_logger: Epoch 89/1000, train_Loss: 9720.6171875, val_Loss: 8263.0244]\n",
      "[2024-03-30 21:32:34,190: INFO: model_logger: Epoch 90/1000, train_Loss: 9639.541015625, val_Loss: 9093.5098]\n",
      "[2024-03-30 21:32:34,389: INFO: model_logger: Epoch 91/1000, train_Loss: 9477.4658203125, val_Loss: 9294.4531]\n",
      "[2024-03-30 21:32:34,655: INFO: model_logger: Epoch 92/1000, train_Loss: 9333.4453125, val_Loss: 8804.5078]\n",
      "[2024-03-30 21:32:34,853: INFO: model_logger: Epoch 93/1000, train_Loss: 9330.2138671875, val_Loss: 8778.1738]\n",
      "[2024-03-30 21:32:35,049: INFO: model_logger: Epoch 94/1000, train_Loss: 9256.59765625, val_Loss: 8902.3047]\n",
      "[2024-03-30 21:32:35,314: INFO: model_logger: Epoch 95/1000, train_Loss: 9157.0205078125, val_Loss: 8385.2227]\n",
      "[2024-03-30 21:32:35,513: INFO: model_logger: Epoch 96/1000, train_Loss: 9079.103515625, val_Loss: 8585.0039]\n",
      "[2024-03-30 21:32:35,715: INFO: model_logger: Epoch 97/1000, train_Loss: 8936.232421875, val_Loss: 8253.9238]\n",
      "[2024-03-30 21:32:35,973: INFO: model_logger: Epoch 98/1000, train_Loss: 8995.4697265625, val_Loss: 7753.6328]\n",
      "[2024-03-30 21:32:36,178: INFO: model_logger: Epoch 99/1000, train_Loss: 8811.908203125, val_Loss: 8965.0137]\n",
      "[2024-03-30 21:32:36,379: INFO: model_logger: Epoch 100/1000, train_Loss: 8904.046875, val_Loss: 8307.0283]\n",
      "[2024-03-30 21:32:36,580: INFO: model_logger: Epoch 101/1000, train_Loss: 8665.1279296875, val_Loss: 8306.2305]\n",
      "[2024-03-30 21:32:36,845: INFO: model_logger: Epoch 102/1000, train_Loss: 8743.5048828125, val_Loss: 8252.2100]\n",
      "[2024-03-30 21:32:37,043: INFO: model_logger: Epoch 103/1000, train_Loss: 8752.3623046875, val_Loss: 8111.1519]\n",
      "[2024-03-30 21:32:37,243: INFO: model_logger: Epoch 104/1000, train_Loss: 8630.6982421875, val_Loss: 8070.3955]\n",
      "[2024-03-30 21:32:37,506: INFO: model_logger: Epoch 105/1000, train_Loss: 8556.2890625, val_Loss: 8547.7275]\n",
      "[2024-03-30 21:32:37,704: INFO: model_logger: Epoch 106/1000, train_Loss: 8555.8173828125, val_Loss: 8349.8398]\n",
      "[2024-03-30 21:32:37,905: INFO: model_logger: Epoch 107/1000, train_Loss: 8549.8427734375, val_Loss: 7987.5405]\n",
      "[2024-03-30 21:32:38,169: INFO: model_logger: Epoch 108/1000, train_Loss: 8432.189453125, val_Loss: 8450.2461]\n",
      "[2024-03-30 21:32:38,371: INFO: model_logger: Epoch 109/1000, train_Loss: 8445.9248046875, val_Loss: 8017.5869]\n",
      "[2024-03-30 21:32:38,574: INFO: model_logger: Epoch 110/1000, train_Loss: 8597.9482421875, val_Loss: 7969.7300]\n",
      "[2024-03-30 21:32:38,771: INFO: model_logger: Epoch 111/1000, train_Loss: 8372.8173828125, val_Loss: 8164.4570]\n",
      "[2024-03-30 21:32:39,066: INFO: model_logger: Epoch 112/1000, train_Loss: 8500.5751953125, val_Loss: 7995.9219]\n",
      "[2024-03-30 21:32:39,274: INFO: model_logger: Epoch 113/1000, train_Loss: 8381.798828125, val_Loss: 7864.9521]\n",
      "[2024-03-30 21:32:39,478: INFO: model_logger: Epoch 114/1000, train_Loss: 8445.775390625, val_Loss: 7826.4150]\n",
      "[2024-03-30 21:32:39,738: INFO: model_logger: Epoch 115/1000, train_Loss: 8341.4140625, val_Loss: 7667.7871]\n",
      "[2024-03-30 21:32:39,942: INFO: model_logger: Epoch 116/1000, train_Loss: 8245.2783203125, val_Loss: 7912.2578]\n",
      "[2024-03-30 21:32:40,141: INFO: model_logger: Epoch 117/1000, train_Loss: 8212.1806640625, val_Loss: 7781.8721]\n",
      "[2024-03-30 21:32:40,424: INFO: model_logger: Epoch 118/1000, train_Loss: 8271.30078125, val_Loss: 8302.9062]\n",
      "[2024-03-30 21:32:40,630: INFO: model_logger: Epoch 119/1000, train_Loss: 8355.9296875, val_Loss: 8200.9746]\n",
      "[2024-03-30 21:32:40,823: INFO: model_logger: Epoch 120/1000, train_Loss: 8324.9853515625, val_Loss: 7614.8330]\n",
      "[2024-03-30 21:32:41,093: INFO: model_logger: Epoch 121/1000, train_Loss: 8060.3779296875, val_Loss: 7991.2305]\n",
      "[2024-03-30 21:32:41,294: INFO: model_logger: Epoch 122/1000, train_Loss: 8106.0654296875, val_Loss: 7936.1265]\n",
      "[2024-03-30 21:32:41,497: INFO: model_logger: Epoch 123/1000, train_Loss: 8230.3837890625, val_Loss: 7774.1172]\n",
      "[2024-03-30 21:32:41,713: INFO: model_logger: Epoch 124/1000, train_Loss: 8235.0244140625, val_Loss: 7873.1733]\n",
      "[2024-03-30 21:32:41,991: INFO: model_logger: Epoch 125/1000, train_Loss: 8154.67333984375, val_Loss: 7935.9219]\n",
      "[2024-03-30 21:32:42,188: INFO: model_logger: Epoch 126/1000, train_Loss: 8333.3125, val_Loss: 7840.9307]\n",
      "[2024-03-30 21:32:42,392: INFO: model_logger: Epoch 127/1000, train_Loss: 8072.380859375, val_Loss: 7626.4727]\n",
      "[2024-03-30 21:32:42,653: INFO: model_logger: Epoch 128/1000, train_Loss: 8109.1328125, val_Loss: 8260.3867]\n",
      "[2024-03-30 21:32:42,852: INFO: model_logger: Epoch 129/1000, train_Loss: 8260.728515625, val_Loss: 8028.3452]\n",
      "[2024-03-30 21:32:43,053: INFO: model_logger: Epoch 130/1000, train_Loss: 8023.65087890625, val_Loss: 7866.8218]\n",
      "[2024-03-30 21:32:43,310: INFO: model_logger: Epoch 131/1000, train_Loss: 8154.09326171875, val_Loss: 7620.3984]\n",
      "[2024-03-30 21:32:43,507: INFO: model_logger: Epoch 132/1000, train_Loss: 8122.81005859375, val_Loss: 7540.6050]\n",
      "[2024-03-30 21:32:43,710: INFO: model_logger: Epoch 133/1000, train_Loss: 8154.50439453125, val_Loss: 8193.7256]\n",
      "[2024-03-30 21:32:43,918: INFO: model_logger: Epoch 134/1000, train_Loss: 8156.771484375, val_Loss: 7850.9590]\n",
      "[2024-03-30 21:32:44,196: INFO: model_logger: Epoch 135/1000, train_Loss: 8193.830078125, val_Loss: 7775.9663]\n",
      "[2024-03-30 21:32:44,396: INFO: model_logger: Epoch 136/1000, train_Loss: 8211.0185546875, val_Loss: 7691.5488]\n",
      "[2024-03-30 21:32:44,591: INFO: model_logger: Epoch 137/1000, train_Loss: 8343.4384765625, val_Loss: 7838.8818]\n",
      "[2024-03-30 21:32:44,851: INFO: model_logger: Epoch 138/1000, train_Loss: 8180.40869140625, val_Loss: 7923.1694]\n",
      "[2024-03-30 21:32:45,047: INFO: model_logger: Epoch 139/1000, train_Loss: 8066.01806640625, val_Loss: 8059.2656]\n",
      "[2024-03-30 21:32:45,239: INFO: model_logger: Epoch 140/1000, train_Loss: 8158.8681640625, val_Loss: 7696.1416]\n",
      "[2024-03-30 21:32:45,493: INFO: model_logger: Epoch 141/1000, train_Loss: 8166.4921875, val_Loss: 7600.3042]\n",
      "[2024-03-30 21:32:45,693: INFO: model_logger: Epoch 142/1000, train_Loss: 8166.27294921875, val_Loss: 7671.4136]\n",
      "[2024-03-30 21:32:45,899: INFO: model_logger: Epoch 143/1000, train_Loss: 8230.3125, val_Loss: 8017.8374]\n",
      "[2024-03-30 21:32:46,162: INFO: model_logger: Epoch 144/1000, train_Loss: 8198.6630859375, val_Loss: 7708.7510]\n",
      "[2024-03-30 21:32:46,359: INFO: model_logger: Epoch 145/1000, train_Loss: 8043.0615234375, val_Loss: 7846.1865]\n",
      "[2024-03-30 21:32:46,559: INFO: model_logger: Epoch 146/1000, train_Loss: 8097.8271484375, val_Loss: 7868.4463]\n",
      "[2024-03-30 21:32:46,755: INFO: model_logger: Epoch 147/1000, train_Loss: 8191.70263671875, val_Loss: 7981.5444]\n",
      "[2024-03-30 21:32:47,016: INFO: model_logger: Epoch 148/1000, train_Loss: 8062.8935546875, val_Loss: 7968.3564]\n",
      "[2024-03-30 21:32:47,217: INFO: model_logger: Epoch 149/1000, train_Loss: 8132.84814453125, val_Loss: 7620.1948]\n",
      "[2024-03-30 21:32:47,425: INFO: model_logger: Epoch 150/1000, train_Loss: 8133.41162109375, val_Loss: 8010.2065]\n",
      "[2024-03-30 21:32:47,678: INFO: model_logger: Epoch 151/1000, train_Loss: 8023.875, val_Loss: 7398.1440]\n",
      "[2024-03-30 21:32:47,876: INFO: model_logger: Epoch 152/1000, train_Loss: 8123.78662109375, val_Loss: 7887.9219]\n",
      "[2024-03-30 21:32:48,079: INFO: model_logger: Epoch 153/1000, train_Loss: 8131.51953125, val_Loss: 7417.4170]\n",
      "[2024-03-30 21:32:48,338: INFO: model_logger: Epoch 154/1000, train_Loss: 8247.373046875, val_Loss: 8015.0840]\n",
      "[2024-03-30 21:32:48,543: INFO: model_logger: Epoch 155/1000, train_Loss: 7913.17431640625, val_Loss: 7958.3804]\n",
      "[2024-03-30 21:32:48,739: INFO: model_logger: Epoch 156/1000, train_Loss: 8126.46484375, val_Loss: 7552.3223]\n",
      "[2024-03-30 21:32:48,953: INFO: model_logger: Epoch 157/1000, train_Loss: 7953.8857421875, val_Loss: 7560.5068]\n",
      "[2024-03-30 21:32:49,233: INFO: model_logger: Epoch 158/1000, train_Loss: 8112.55908203125, val_Loss: 7839.4365]\n",
      "[2024-03-30 21:32:49,431: INFO: model_logger: Epoch 159/1000, train_Loss: 8068.07177734375, val_Loss: 7885.9346]\n",
      "[2024-03-30 21:32:49,626: INFO: model_logger: Epoch 160/1000, train_Loss: 8018.28662109375, val_Loss: 7543.8945]\n",
      "[2024-03-30 21:32:49,907: INFO: model_logger: Epoch 161/1000, train_Loss: 8042.9140625, val_Loss: 7768.1694]\n",
      "[2024-03-30 21:32:50,121: INFO: model_logger: Epoch 162/1000, train_Loss: 8052.375, val_Loss: 7962.5557]\n",
      "[2024-03-30 21:32:50,344: INFO: model_logger: Epoch 163/1000, train_Loss: 8026.14794921875, val_Loss: 7564.9468]\n",
      "[2024-03-30 21:32:50,652: INFO: model_logger: Epoch 164/1000, train_Loss: 7910.03125, val_Loss: 7648.3496]\n",
      "[2024-03-30 21:32:50,883: INFO: model_logger: Epoch 165/1000, train_Loss: 8114.873046875, val_Loss: 7675.8740]\n",
      "[2024-03-30 21:32:51,128: INFO: model_logger: Epoch 166/1000, train_Loss: 8010.60693359375, val_Loss: 7714.2007]\n",
      "[2024-03-30 21:32:51,418: INFO: model_logger: Epoch 167/1000, train_Loss: 8111.80419921875, val_Loss: 7857.3311]\n",
      "[2024-03-30 21:32:51,654: INFO: model_logger: Epoch 168/1000, train_Loss: 8031.43896484375, val_Loss: 7924.1968]\n",
      "[2024-03-30 21:32:51,874: INFO: model_logger: Epoch 169/1000, train_Loss: 8003.72412109375, val_Loss: 7780.4727]\n",
      "[2024-03-30 21:32:52,104: INFO: model_logger: Epoch 170/1000, train_Loss: 8088.1015625, val_Loss: 7933.7476]\n",
      "[2024-03-30 21:32:52,397: INFO: model_logger: Epoch 171/1000, train_Loss: 8112.21826171875, val_Loss: 7867.9531]\n",
      "[2024-03-30 21:32:52,618: INFO: model_logger: Epoch 172/1000, train_Loss: 7968.98876953125, val_Loss: 7892.5210]\n",
      "[2024-03-30 21:32:52,823: INFO: model_logger: Epoch 173/1000, train_Loss: 7986.18896484375, val_Loss: 8044.3975]\n",
      "[2024-03-30 21:32:53,095: INFO: model_logger: Epoch 174/1000, train_Loss: 7889.2451171875, val_Loss: 7849.0132]\n",
      "[2024-03-30 21:32:53,312: INFO: model_logger: Epoch 175/1000, train_Loss: 8021.091796875, val_Loss: 7418.1025]\n",
      "[2024-03-30 21:32:53,536: INFO: model_logger: Epoch 176/1000, train_Loss: 8249.029296875, val_Loss: 8307.7227]\n",
      "[2024-03-30 21:32:53,835: INFO: model_logger: Epoch 177/1000, train_Loss: 8093.95751953125, val_Loss: 7724.8379]\n",
      "[2024-03-30 21:32:54,078: INFO: model_logger: Epoch 178/1000, train_Loss: 8194.5322265625, val_Loss: 7746.4443]\n",
      "[2024-03-30 21:32:54,284: INFO: model_logger: Epoch 179/1000, train_Loss: 7969.9921875, val_Loss: 8100.2319]\n",
      "[2024-03-30 21:32:54,489: INFO: model_logger: Epoch 180/1000, train_Loss: 8132.34619140625, val_Loss: 8224.5254]\n",
      "[2024-03-30 21:32:54,751: INFO: model_logger: Epoch 181/1000, train_Loss: 8078.03515625, val_Loss: 7848.6655]\n",
      "[2024-03-30 21:32:54,961: INFO: model_logger: Epoch 182/1000, train_Loss: 8089.04052734375, val_Loss: 7809.5425]\n",
      "[2024-03-30 21:32:55,169: INFO: model_logger: Epoch 183/1000, train_Loss: 8012.08349609375, val_Loss: 7619.0938]\n",
      "[2024-03-30 21:32:55,444: INFO: model_logger: Epoch 184/1000, train_Loss: 8060.60693359375, val_Loss: 7649.3438]\n",
      "[2024-03-30 21:32:55,654: INFO: model_logger: Epoch 185/1000, train_Loss: 7938.7509765625, val_Loss: 7912.0283]\n",
      "[2024-03-30 21:32:55,861: INFO: model_logger: Epoch 186/1000, train_Loss: 8017.5615234375, val_Loss: 7599.7393]\n",
      "[2024-03-30 21:32:56,133: INFO: model_logger: Epoch 187/1000, train_Loss: 8034.26220703125, val_Loss: 7382.1865]\n",
      "[2024-03-30 21:32:56,344: INFO: model_logger: Epoch 188/1000, train_Loss: 8069.068359375, val_Loss: 7536.8877]\n",
      "[2024-03-30 21:32:56,566: INFO: model_logger: Epoch 189/1000, train_Loss: 7922.734375, val_Loss: 7503.7534]\n",
      "[2024-03-30 21:32:56,872: INFO: model_logger: Epoch 190/1000, train_Loss: 7949.66015625, val_Loss: 7413.8828]\n",
      "[2024-03-30 21:32:57,091: INFO: model_logger: Epoch 191/1000, train_Loss: 7971.24169921875, val_Loss: 7513.1904]\n",
      "[2024-03-30 21:32:57,299: INFO: model_logger: Epoch 192/1000, train_Loss: 7861.2490234375, val_Loss: 7780.2676]\n",
      "[2024-03-30 21:32:57,500: INFO: model_logger: Epoch 193/1000, train_Loss: 8064.4951171875, val_Loss: 7423.4062]\n",
      "[2024-03-30 21:32:57,778: INFO: model_logger: Epoch 194/1000, train_Loss: 8022.109375, val_Loss: 7566.4761]\n",
      "[2024-03-30 21:32:57,987: INFO: model_logger: Epoch 195/1000, train_Loss: 7979.943359375, val_Loss: 7384.5225]\n",
      "[2024-03-30 21:32:58,187: INFO: model_logger: Epoch 196/1000, train_Loss: 8059.36181640625, val_Loss: 7602.3789]\n",
      "[2024-03-30 21:32:58,464: INFO: model_logger: Epoch 197/1000, train_Loss: 7980.99658203125, val_Loss: 7438.7402]\n",
      "[2024-03-30 21:32:58,672: INFO: model_logger: Epoch 198/1000, train_Loss: 7920.48193359375, val_Loss: 7808.8706]\n",
      "[2024-03-30 21:32:58,897: INFO: model_logger: Epoch 199/1000, train_Loss: 7976.65771484375, val_Loss: 7684.7041]\n",
      "[2024-03-30 21:32:59,182: INFO: model_logger: Epoch 200/1000, train_Loss: 7949.7509765625, val_Loss: 7405.7832]\n",
      "[2024-03-30 21:32:59,384: INFO: model_logger: Epoch 201/1000, train_Loss: 7956.734375, val_Loss: 7305.6641]\n",
      "[2024-03-30 21:32:59,584: INFO: model_logger: Epoch 202/1000, train_Loss: 8101.5712890625, val_Loss: 7733.1523]\n",
      "[2024-03-30 21:32:59,782: INFO: model_logger: Epoch 203/1000, train_Loss: 8137.193359375, val_Loss: 7565.2188]\n",
      "[2024-03-30 21:33:00,065: INFO: model_logger: Epoch 204/1000, train_Loss: 8018.20703125, val_Loss: 7865.4292]\n",
      "[2024-03-30 21:33:00,259: INFO: model_logger: Epoch 205/1000, train_Loss: 7975.3916015625, val_Loss: 8000.1289]\n",
      "[2024-03-30 21:33:00,468: INFO: model_logger: Epoch 206/1000, train_Loss: 7970.4140625, val_Loss: 7341.3545]\n",
      "[2024-03-30 21:33:00,733: INFO: model_logger: Epoch 207/1000, train_Loss: 7876.52294921875, val_Loss: 7839.3320]\n",
      "[2024-03-30 21:33:00,940: INFO: model_logger: Epoch 208/1000, train_Loss: 8043.36181640625, val_Loss: 7918.2002]\n",
      "[2024-03-30 21:33:01,147: INFO: model_logger: Epoch 209/1000, train_Loss: 7915.58349609375, val_Loss: 7715.9058]\n",
      "[2024-03-30 21:33:01,425: INFO: model_logger: Epoch 210/1000, train_Loss: 8054.4462890625, val_Loss: 7454.8330]\n",
      "[2024-03-30 21:33:01,620: INFO: model_logger: Epoch 211/1000, train_Loss: 7982.4560546875, val_Loss: 7589.7417]\n",
      "[2024-03-30 21:33:01,814: INFO: model_logger: Epoch 212/1000, train_Loss: 8017.10693359375, val_Loss: 7619.3076]\n",
      "[2024-03-30 21:33:02,080: INFO: model_logger: Epoch 213/1000, train_Loss: 8051.8125, val_Loss: 7317.7339]\n",
      "[2024-03-30 21:33:02,274: INFO: model_logger: Epoch 214/1000, train_Loss: 7958.09375, val_Loss: 7755.3726]\n",
      "[2024-03-30 21:33:02,465: INFO: model_logger: Epoch 215/1000, train_Loss: 8035.06640625, val_Loss: 7726.0859]\n",
      "[2024-03-30 21:33:02,662: INFO: model_logger: Epoch 216/1000, train_Loss: 7891.31494140625, val_Loss: 7453.8115]\n",
      "[2024-03-30 21:33:02,917: INFO: model_logger: Epoch 217/1000, train_Loss: 7853.69970703125, val_Loss: 7470.1265]\n",
      "[2024-03-30 21:33:03,123: INFO: model_logger: Epoch 218/1000, train_Loss: 8073.23876953125, val_Loss: 7693.9287]\n",
      "[2024-03-30 21:33:03,325: INFO: model_logger: Epoch 219/1000, train_Loss: 7925.1708984375, val_Loss: 7493.0288]\n",
      "[2024-03-30 21:33:03,591: INFO: model_logger: Epoch 220/1000, train_Loss: 7859.74365234375, val_Loss: 7715.7749]\n",
      "[2024-03-30 21:33:03,790: INFO: model_logger: Epoch 221/1000, train_Loss: 7996.87939453125, val_Loss: 7802.3452]\n",
      "[2024-03-30 21:33:04,013: INFO: model_logger: Epoch 222/1000, train_Loss: 7895.615234375, val_Loss: 7962.6670]\n",
      "[2024-03-30 21:33:04,284: INFO: model_logger: Epoch 223/1000, train_Loss: 7949.56787109375, val_Loss: 7650.9941]\n",
      "[2024-03-30 21:33:04,484: INFO: model_logger: Epoch 224/1000, train_Loss: 7909.2587890625, val_Loss: 7594.5752]\n",
      "[2024-03-30 21:33:04,690: INFO: model_logger: Epoch 225/1000, train_Loss: 7974.08349609375, val_Loss: 7509.2085]\n",
      "[2024-03-30 21:33:04,894: INFO: model_logger: Epoch 226/1000, train_Loss: 8035.97021484375, val_Loss: 7749.3984]\n",
      "[2024-03-30 21:33:05,157: INFO: model_logger: Epoch 227/1000, train_Loss: 7933.77490234375, val_Loss: 7755.4912]\n",
      "[2024-03-30 21:33:05,360: INFO: model_logger: Epoch 228/1000, train_Loss: 7961.76220703125, val_Loss: 7779.1387]\n",
      "[2024-03-30 21:33:05,560: INFO: model_logger: Epoch 229/1000, train_Loss: 7994.4921875, val_Loss: 7639.5713]\n",
      "[2024-03-30 21:33:05,822: INFO: model_logger: Epoch 230/1000, train_Loss: 7842.8046875, val_Loss: 7681.6523]\n",
      "[2024-03-30 21:33:06,019: INFO: model_logger: Epoch 231/1000, train_Loss: 7888.88818359375, val_Loss: 7445.9297]\n",
      "[2024-03-30 21:33:06,218: INFO: model_logger: Epoch 232/1000, train_Loss: 7960.90234375, val_Loss: 7577.1504]\n",
      "[2024-03-30 21:33:06,480: INFO: model_logger: Epoch 233/1000, train_Loss: 7851.2421875, val_Loss: 7511.1948]\n",
      "[2024-03-30 21:33:06,678: INFO: model_logger: Epoch 234/1000, train_Loss: 7946.826171875, val_Loss: 7792.6396]\n",
      "[2024-03-30 21:33:06,875: INFO: model_logger: Epoch 235/1000, train_Loss: 7933.13427734375, val_Loss: 7538.4116]\n",
      "[2024-03-30 21:33:07,133: INFO: model_logger: Epoch 236/1000, train_Loss: 7857.72412109375, val_Loss: 7927.5781]\n",
      "[2024-03-30 21:33:07,338: INFO: model_logger: Epoch 237/1000, train_Loss: 8055.02587890625, val_Loss: 7813.4180]\n",
      "[2024-03-30 21:33:07,551: INFO: model_logger: Epoch 238/1000, train_Loss: 7994.2978515625, val_Loss: 7558.0522]\n",
      "[2024-03-30 21:33:07,752: INFO: model_logger: Epoch 239/1000, train_Loss: 7970.3662109375, val_Loss: 7679.0918]\n",
      "[2024-03-30 21:33:08,016: INFO: model_logger: Epoch 240/1000, train_Loss: 7846.22119140625, val_Loss: 7830.5811]\n",
      "[2024-03-30 21:33:08,216: INFO: model_logger: Epoch 241/1000, train_Loss: 7839.36376953125, val_Loss: 7678.6611]\n",
      "[2024-03-30 21:33:08,416: INFO: model_logger: Epoch 242/1000, train_Loss: 7814.28125, val_Loss: 7693.9854]\n",
      "[2024-03-30 21:33:08,674: INFO: model_logger: Epoch 243/1000, train_Loss: 7958.14794921875, val_Loss: 7603.0078]\n",
      "[2024-03-30 21:33:08,872: INFO: model_logger: Epoch 244/1000, train_Loss: 8014.45068359375, val_Loss: 7461.9678]\n",
      "[2024-03-30 21:33:09,083: INFO: model_logger: Epoch 245/1000, train_Loss: 8000.14013671875, val_Loss: 7672.0679]\n",
      "[2024-03-30 21:33:09,351: INFO: model_logger: Epoch 246/1000, train_Loss: 7962.55419921875, val_Loss: 7839.2646]\n",
      "[2024-03-30 21:33:09,553: INFO: model_logger: Epoch 247/1000, train_Loss: 8013.81689453125, val_Loss: 7638.7852]\n",
      "[2024-03-30 21:33:09,753: INFO: model_logger: Epoch 248/1000, train_Loss: 7935.58544921875, val_Loss: 7682.1172]\n",
      "[2024-03-30 21:33:09,962: INFO: model_logger: Epoch 249/1000, train_Loss: 7883.34814453125, val_Loss: 7978.9370]\n",
      "[2024-03-30 21:33:10,220: INFO: model_logger: Epoch 250/1000, train_Loss: 7868.17724609375, val_Loss: 7985.3276]\n",
      "[2024-03-30 21:33:10,416: INFO: model_logger: Epoch 251/1000, train_Loss: 7827.26025390625, val_Loss: 7558.2397]\n",
      "[2024-03-30 21:33:10,630: INFO: model_logger: Epoch 252/1000, train_Loss: 7883.34033203125, val_Loss: 8028.1191]\n",
      "[2024-03-30 21:33:10,897: INFO: model_logger: Epoch 253/1000, train_Loss: 7966.583984375, val_Loss: 7828.2788]\n",
      "[2024-03-30 21:33:11,088: INFO: model_logger: Epoch 254/1000, train_Loss: 7855.88427734375, val_Loss: 8070.8491]\n",
      "[2024-03-30 21:33:11,281: INFO: model_logger: Epoch 255/1000, train_Loss: 7906.4716796875, val_Loss: 8149.4951]\n",
      "[2024-03-30 21:33:11,536: INFO: model_logger: Epoch 256/1000, train_Loss: 7909.73681640625, val_Loss: 7633.3359]\n",
      "[2024-03-30 21:33:11,737: INFO: model_logger: Epoch 257/1000, train_Loss: 8004.1552734375, val_Loss: 7634.6025]\n",
      "[2024-03-30 21:33:11,935: INFO: model_logger: Epoch 258/1000, train_Loss: 7917.84375, val_Loss: 7795.3115]\n",
      "[2024-03-30 21:33:12,189: INFO: model_logger: Epoch 259/1000, train_Loss: 7907.4638671875, val_Loss: 8043.3999]\n",
      "[2024-03-30 21:33:12,383: INFO: model_logger: Epoch 260/1000, train_Loss: 7843.2900390625, val_Loss: 7703.0659]\n",
      "[2024-03-30 21:33:12,579: INFO: model_logger: Epoch 261/1000, train_Loss: 7829.00732421875, val_Loss: 7741.3433]\n",
      "[2024-03-30 21:33:12,779: INFO: model_logger: Epoch 262/1000, train_Loss: 7971.85400390625, val_Loss: 7746.7881]\n",
      "[2024-03-30 21:33:13,110: INFO: model_logger: Epoch 263/1000, train_Loss: 8014.34326171875, val_Loss: 7741.8623]\n",
      "[2024-03-30 21:33:13,305: INFO: model_logger: Epoch 264/1000, train_Loss: 7900.2607421875, val_Loss: 7833.9482]\n",
      "[2024-03-30 21:33:13,501: INFO: model_logger: Epoch 265/1000, train_Loss: 7795.521484375, val_Loss: 7471.1089]\n",
      "[2024-03-30 21:33:13,764: INFO: model_logger: Epoch 266/1000, train_Loss: 7872.26025390625, val_Loss: 7980.3506]\n",
      "[2024-03-30 21:33:13,968: INFO: model_logger: Epoch 267/1000, train_Loss: 7912.0087890625, val_Loss: 7707.6904]\n",
      "[2024-03-30 21:33:14,174: INFO: model_logger: Epoch 268/1000, train_Loss: 7819.43115234375, val_Loss: 7727.0698]\n",
      "[2024-03-30 21:33:14,436: INFO: model_logger: Epoch 269/1000, train_Loss: 7948.92724609375, val_Loss: 7783.4976]\n",
      "[2024-03-30 21:33:14,631: INFO: model_logger: Epoch 270/1000, train_Loss: 7915.26171875, val_Loss: 7734.7393]\n",
      "[2024-03-30 21:33:14,829: INFO: model_logger: Epoch 271/1000, train_Loss: 8035.0244140625, val_Loss: 7574.4077]\n",
      "[2024-03-30 21:33:15,020: INFO: model_logger: Epoch 272/1000, train_Loss: 7975.50244140625, val_Loss: 7611.6475]\n",
      "[2024-03-30 21:33:15,275: INFO: model_logger: Epoch 273/1000, train_Loss: 7968.146484375, val_Loss: 7854.2959]\n",
      "[2024-03-30 21:33:15,469: INFO: model_logger: Epoch 274/1000, train_Loss: 7929.8203125, val_Loss: 7710.8779]\n",
      "[2024-03-30 21:33:15,663: INFO: model_logger: Epoch 275/1000, train_Loss: 7932.66064453125, val_Loss: 7863.2764]\n",
      "[2024-03-30 21:33:15,926: INFO: model_logger: Epoch 276/1000, train_Loss: 7938.9873046875, val_Loss: 8144.9370]\n",
      "[2024-03-30 21:33:16,131: INFO: model_logger: Epoch 277/1000, train_Loss: 7908.7763671875, val_Loss: 7473.8633]\n",
      "[2024-03-30 21:33:16,340: INFO: model_logger: Epoch 278/1000, train_Loss: 7844.4873046875, val_Loss: 7512.6582]\n",
      "[2024-03-30 21:33:16,597: INFO: model_logger: Epoch 279/1000, train_Loss: 7809.4697265625, val_Loss: 7824.7925]\n",
      "[2024-03-30 21:33:16,788: INFO: model_logger: Epoch 280/1000, train_Loss: 7769.2998046875, val_Loss: 7660.2554]\n",
      "[2024-03-30 21:33:17,004: INFO: model_logger: Epoch 281/1000, train_Loss: 7864.421875, val_Loss: 7649.5547]\n",
      "[2024-03-30 21:33:17,271: INFO: model_logger: Epoch 282/1000, train_Loss: 7832.36669921875, val_Loss: 7781.5366]\n",
      "[2024-03-30 21:33:17,496: INFO: model_logger: Epoch 283/1000, train_Loss: 7905.89013671875, val_Loss: 8091.6523]\n",
      "[2024-03-30 21:33:17,699: INFO: model_logger: Epoch 284/1000, train_Loss: 7910.04833984375, val_Loss: 7896.4038]\n",
      "[2024-03-30 21:33:17,902: INFO: model_logger: Epoch 285/1000, train_Loss: 7920.669921875, val_Loss: 8003.0498]\n",
      "[2024-03-30 21:33:18,181: INFO: model_logger: Epoch 286/1000, train_Loss: 7833.240234375, val_Loss: 8206.6152]\n",
      "[2024-03-30 21:33:18,377: INFO: model_logger: Epoch 287/1000, train_Loss: 7822.591796875, val_Loss: 7760.6929]\n",
      "[2024-03-30 21:33:18,578: INFO: model_logger: Epoch 288/1000, train_Loss: 7837.3671875, val_Loss: 7748.4844]\n",
      "[2024-03-30 21:33:18,840: INFO: model_logger: Epoch 289/1000, train_Loss: 7948.81005859375, val_Loss: 8064.2539]\n",
      "[2024-03-30 21:33:19,100: INFO: model_logger: Epoch 290/1000, train_Loss: 7875.66796875, val_Loss: 7791.4722]\n",
      "[2024-03-30 21:33:19,346: INFO: model_logger: Epoch 291/1000, train_Loss: 7825.16015625, val_Loss: 7911.4717]\n",
      "[2024-03-30 21:33:19,620: INFO: model_logger: Epoch 292/1000, train_Loss: 7771.8525390625, val_Loss: 7658.5547]\n",
      "[2024-03-30 21:33:19,832: INFO: model_logger: Epoch 293/1000, train_Loss: 7916.93701171875, val_Loss: 7893.6831]\n",
      "[2024-03-30 21:33:20,036: INFO: model_logger: Epoch 294/1000, train_Loss: 7719.93359375, val_Loss: 7744.1104]\n",
      "[2024-03-30 21:33:20,240: INFO: model_logger: Epoch 295/1000, train_Loss: 7769.9921875, val_Loss: 7821.0947]\n",
      "[2024-03-30 21:33:20,513: INFO: model_logger: Epoch 296/1000, train_Loss: 7821.01171875, val_Loss: 7918.9780]\n",
      "[2024-03-30 21:33:20,714: INFO: model_logger: Epoch 297/1000, train_Loss: 7816.84619140625, val_Loss: 7963.6572]\n",
      "[2024-03-30 21:33:20,908: INFO: model_logger: Epoch 298/1000, train_Loss: 7870.7421875, val_Loss: 7607.4897]\n",
      "[2024-03-30 21:33:21,182: INFO: model_logger: Epoch 299/1000, train_Loss: 7651.7890625, val_Loss: 7663.5483]\n",
      "[2024-03-30 21:33:21,421: INFO: model_logger: Epoch 300/1000, train_Loss: 7816.95556640625, val_Loss: 7521.0439]\n",
      "[2024-03-30 21:33:21,632: INFO: model_logger: Epoch 301/1000, train_Loss: 7866.16064453125, val_Loss: 8091.8979]\n",
      "[2024-03-30 21:33:21,910: INFO: model_logger: Epoch 302/1000, train_Loss: 7952.64501953125, val_Loss: 8045.7671]\n",
      "[2024-03-30 21:33:22,106: INFO: model_logger: Epoch 303/1000, train_Loss: 7854.607421875, val_Loss: 8060.0586]\n",
      "[2024-03-30 21:33:22,314: INFO: model_logger: Epoch 304/1000, train_Loss: 7862.849609375, val_Loss: 7728.6533]\n",
      "[2024-03-30 21:33:22,587: INFO: model_logger: Epoch 305/1000, train_Loss: 7951.76318359375, val_Loss: 7284.8359]\n",
      "[2024-03-30 21:33:22,801: INFO: model_logger: Epoch 306/1000, train_Loss: 7917.6044921875, val_Loss: 7825.4854]\n",
      "[2024-03-30 21:33:23,010: INFO: model_logger: Epoch 307/1000, train_Loss: 7793.41796875, val_Loss: 7718.5928]\n",
      "[2024-03-30 21:33:23,217: INFO: model_logger: Epoch 308/1000, train_Loss: 7825.1796875, val_Loss: 7548.3140]\n",
      "[2024-03-30 21:33:23,500: INFO: model_logger: Epoch 309/1000, train_Loss: 7823.2138671875, val_Loss: 7421.2295]\n",
      "[2024-03-30 21:33:23,714: INFO: model_logger: Epoch 310/1000, train_Loss: 7960.1494140625, val_Loss: 7911.6201]\n",
      "[2024-03-30 21:33:23,933: INFO: model_logger: Epoch 311/1000, train_Loss: 7700.95703125, val_Loss: 7545.6108]\n",
      "[2024-03-30 21:33:24,225: INFO: model_logger: Epoch 312/1000, train_Loss: 8001.34912109375, val_Loss: 7263.3101]\n",
      "[2024-03-30 21:33:24,434: INFO: model_logger: Epoch 313/1000, train_Loss: 7852.22802734375, val_Loss: 7658.0439]\n",
      "[2024-03-30 21:33:24,647: INFO: model_logger: Epoch 314/1000, train_Loss: 7752.6875, val_Loss: 7228.1343]\n",
      "[2024-03-30 21:33:24,923: INFO: model_logger: Epoch 315/1000, train_Loss: 7765.4873046875, val_Loss: 7885.6460]\n",
      "[2024-03-30 21:33:25,129: INFO: model_logger: Epoch 316/1000, train_Loss: 7698.60888671875, val_Loss: 7749.1865]\n",
      "[2024-03-30 21:33:25,331: INFO: model_logger: Epoch 317/1000, train_Loss: 7744.77294921875, val_Loss: 7736.5972]\n",
      "[2024-03-30 21:33:25,549: INFO: model_logger: Epoch 318/1000, train_Loss: 7806.3046875, val_Loss: 8153.2510]\n",
      "[2024-03-30 21:33:25,829: INFO: model_logger: Epoch 319/1000, train_Loss: 7712.099609375, val_Loss: 7761.5249]\n",
      "[2024-03-30 21:33:26,037: INFO: model_logger: Epoch 320/1000, train_Loss: 7802.97607421875, val_Loss: 7755.5972]\n",
      "[2024-03-30 21:33:26,243: INFO: model_logger: Epoch 321/1000, train_Loss: 7939.12646484375, val_Loss: 7825.6289]\n",
      "[2024-03-30 21:33:26,516: INFO: model_logger: Epoch 322/1000, train_Loss: 7839.8115234375, val_Loss: 7777.3027]\n",
      "[2024-03-30 21:33:26,738: INFO: model_logger: Epoch 323/1000, train_Loss: 7957.23095703125, val_Loss: 7523.5293]\n",
      "[2024-03-30 21:33:26,946: INFO: model_logger: Epoch 324/1000, train_Loss: 7838.7529296875, val_Loss: 7661.5967]\n",
      "[2024-03-30 21:33:27,242: INFO: model_logger: Epoch 325/1000, train_Loss: 7795.3935546875, val_Loss: 7561.4180]\n",
      "[2024-03-30 21:33:27,465: INFO: model_logger: Epoch 326/1000, train_Loss: 7748.7841796875, val_Loss: 7548.5850]\n",
      "[2024-03-30 21:33:27,699: INFO: model_logger: Epoch 327/1000, train_Loss: 7827.79052734375, val_Loss: 7682.7266]\n",
      "[2024-03-30 21:33:27,987: INFO: model_logger: Epoch 328/1000, train_Loss: 7796.498046875, val_Loss: 8082.5088]\n",
      "[2024-03-30 21:33:28,235: INFO: model_logger: Epoch 329/1000, train_Loss: 7625.95458984375, val_Loss: 8246.2695]\n",
      "[2024-03-30 21:33:28,449: INFO: model_logger: Epoch 330/1000, train_Loss: 7771.125, val_Loss: 7733.7891]\n",
      "[2024-03-30 21:33:28,670: INFO: model_logger: Epoch 331/1000, train_Loss: 7758.0859375, val_Loss: 7828.8726]\n",
      "[2024-03-30 21:33:28,990: INFO: model_logger: Epoch 332/1000, train_Loss: 7757.99365234375, val_Loss: 7866.6260]\n",
      "[2024-03-30 21:33:29,247: INFO: model_logger: Epoch 333/1000, train_Loss: 7784.31005859375, val_Loss: 7643.6533]\n",
      "[2024-03-30 21:33:29,466: INFO: model_logger: Epoch 334/1000, train_Loss: 7873.18505859375, val_Loss: 7422.3877]\n",
      "[2024-03-30 21:33:29,774: INFO: model_logger: Epoch 335/1000, train_Loss: 7789.29345703125, val_Loss: 7296.4795]\n",
      "[2024-03-30 21:33:29,995: INFO: model_logger: Epoch 336/1000, train_Loss: 7815.78271484375, val_Loss: 7804.5156]\n",
      "[2024-03-30 21:33:30,236: INFO: model_logger: Epoch 337/1000, train_Loss: 7797.51171875, val_Loss: 7847.0156]\n",
      "[2024-03-30 21:33:30,511: INFO: model_logger: Epoch 338/1000, train_Loss: 7743.88525390625, val_Loss: 7673.9316]\n",
      "[2024-03-30 21:33:30,719: INFO: model_logger: Epoch 339/1000, train_Loss: 7637.2197265625, val_Loss: 7653.4141]\n",
      "[2024-03-30 21:33:30,966: INFO: model_logger: Epoch 340/1000, train_Loss: 7825.38818359375, val_Loss: 7771.9409]\n",
      "[2024-03-30 21:33:31,182: INFO: model_logger: Epoch 341/1000, train_Loss: 7837.66357421875, val_Loss: 7745.1494]\n",
      "[2024-03-30 21:33:31,468: INFO: model_logger: Epoch 342/1000, train_Loss: 7791.4375, val_Loss: 7992.3740]\n",
      "[2024-03-30 21:33:31,698: INFO: model_logger: Epoch 343/1000, train_Loss: 7831.22900390625, val_Loss: 7528.9390]\n",
      "[2024-03-30 21:33:31,930: INFO: model_logger: Epoch 344/1000, train_Loss: 7795.33740234375, val_Loss: 7698.1694]\n",
      "[2024-03-30 21:33:32,218: INFO: model_logger: Epoch 345/1000, train_Loss: 7934.68359375, val_Loss: 7901.8682]\n",
      "[2024-03-30 21:33:32,432: INFO: model_logger: Epoch 346/1000, train_Loss: 7633.98046875, val_Loss: 8088.7998]\n",
      "[2024-03-30 21:33:32,655: INFO: model_logger: Epoch 347/1000, train_Loss: 7884.943359375, val_Loss: 7720.2202]\n",
      "[2024-03-30 21:33:32,948: INFO: model_logger: Epoch 348/1000, train_Loss: 7761.53857421875, val_Loss: 7882.9312]\n",
      "[2024-03-30 21:33:33,177: INFO: model_logger: Epoch 349/1000, train_Loss: 7714.5966796875, val_Loss: 7723.8687]\n",
      "[2024-03-30 21:33:33,388: INFO: model_logger: Epoch 350/1000, train_Loss: 7757.3828125, val_Loss: 7611.1953]\n",
      "[2024-03-30 21:33:33,676: INFO: model_logger: Epoch 351/1000, train_Loss: 7818.8544921875, val_Loss: 7639.4326]\n",
      "[2024-03-30 21:33:33,909: INFO: model_logger: Epoch 352/1000, train_Loss: 7819.9931640625, val_Loss: 7889.1030]\n",
      "[2024-03-30 21:33:34,188: INFO: model_logger: Epoch 353/1000, train_Loss: 7861.23876953125, val_Loss: 7699.2847]\n",
      "[2024-03-30 21:33:34,414: INFO: model_logger: Epoch 354/1000, train_Loss: 7801.94775390625, val_Loss: 7679.7451]\n",
      "[2024-03-30 21:33:34,703: INFO: model_logger: Epoch 355/1000, train_Loss: 8039.333984375, val_Loss: 7461.3887]\n",
      "[2024-03-30 21:33:34,913: INFO: model_logger: Epoch 356/1000, train_Loss: 7769.115234375, val_Loss: 7630.7090]\n",
      "[2024-03-30 21:33:35,124: INFO: model_logger: Epoch 357/1000, train_Loss: 7906.36669921875, val_Loss: 7161.5635]\n",
      "[2024-03-30 21:33:35,400: INFO: model_logger: Epoch 358/1000, train_Loss: 7801.388671875, val_Loss: 7326.8120]\n",
      "[2024-03-30 21:33:35,612: INFO: model_logger: Epoch 359/1000, train_Loss: 7797.29931640625, val_Loss: 7658.4233]\n",
      "[2024-03-30 21:33:35,819: INFO: model_logger: Epoch 360/1000, train_Loss: 7811.0478515625, val_Loss: 7980.4609]\n",
      "[2024-03-30 21:33:36,093: INFO: model_logger: Epoch 361/1000, train_Loss: 7815.357421875, val_Loss: 7626.0073]\n",
      "[2024-03-30 21:33:36,313: INFO: model_logger: Epoch 362/1000, train_Loss: 7818.54443359375, val_Loss: 7735.7593]\n",
      "[2024-03-30 21:33:36,526: INFO: model_logger: Epoch 363/1000, train_Loss: 7803.79638671875, val_Loss: 7436.2910]\n",
      "[2024-03-30 21:33:36,731: INFO: model_logger: Epoch 364/1000, train_Loss: 7827.77587890625, val_Loss: 7550.7964]\n",
      "[2024-03-30 21:33:36,997: INFO: model_logger: Epoch 365/1000, train_Loss: 7762.3671875, val_Loss: 7944.5977]\n",
      "[2024-03-30 21:33:37,203: INFO: model_logger: Epoch 366/1000, train_Loss: 7696.421875, val_Loss: 7751.8140]\n",
      "[2024-03-30 21:33:37,419: INFO: model_logger: Epoch 367/1000, train_Loss: 7604.0537109375, val_Loss: 8022.3179]\n",
      "[2024-03-30 21:33:37,696: INFO: model_logger: Epoch 368/1000, train_Loss: 7849.2041015625, val_Loss: 7644.6279]\n",
      "[2024-03-30 21:33:37,907: INFO: model_logger: Epoch 369/1000, train_Loss: 7813.48828125, val_Loss: 7979.4443]\n",
      "[2024-03-30 21:33:38,110: INFO: model_logger: Epoch 370/1000, train_Loss: 7683.05224609375, val_Loss: 8122.7764]\n",
      "[2024-03-30 21:33:38,393: INFO: model_logger: Epoch 371/1000, train_Loss: 7872.14599609375, val_Loss: 7748.3584]\n",
      "[2024-03-30 21:33:38,604: INFO: model_logger: Epoch 372/1000, train_Loss: 7856.7099609375, val_Loss: 7733.2959]\n",
      "[2024-03-30 21:33:38,811: INFO: model_logger: Epoch 373/1000, train_Loss: 7740.68359375, val_Loss: 7446.4971]\n",
      "[2024-03-30 21:33:39,107: INFO: model_logger: Epoch 374/1000, train_Loss: 7659.70263671875, val_Loss: 7870.3140]\n",
      "[2024-03-30 21:33:39,324: INFO: model_logger: Epoch 375/1000, train_Loss: 7826.90869140625, val_Loss: 7399.5059]\n",
      "[2024-03-30 21:33:39,544: INFO: model_logger: Epoch 376/1000, train_Loss: 7748.5712890625, val_Loss: 7592.1797]\n",
      "[2024-03-30 21:33:39,758: INFO: model_logger: Epoch 377/1000, train_Loss: 7679.5791015625, val_Loss: 7438.4004]\n",
      "[2024-03-30 21:33:40,025: INFO: model_logger: Epoch 378/1000, train_Loss: 7797.93701171875, val_Loss: 7757.2139]\n",
      "[2024-03-30 21:33:40,233: INFO: model_logger: Epoch 379/1000, train_Loss: 7768.46337890625, val_Loss: 7775.7285]\n",
      "[2024-03-30 21:33:40,439: INFO: model_logger: Epoch 380/1000, train_Loss: 7935.94921875, val_Loss: 7891.8271]\n",
      "[2024-03-30 21:33:40,713: INFO: model_logger: Epoch 381/1000, train_Loss: 7790.1396484375, val_Loss: 7433.9507]\n",
      "[2024-03-30 21:33:40,910: INFO: model_logger: Epoch 382/1000, train_Loss: 7723.78271484375, val_Loss: 7840.6055]\n",
      "[2024-03-30 21:33:41,111: INFO: model_logger: Epoch 383/1000, train_Loss: 7737.04150390625, val_Loss: 7796.5762]\n",
      "[2024-03-30 21:33:41,378: INFO: model_logger: Epoch 384/1000, train_Loss: 7695.482421875, val_Loss: 7386.6650]\n",
      "[2024-03-30 21:33:41,589: INFO: model_logger: Epoch 385/1000, train_Loss: 7760.92431640625, val_Loss: 7722.4663]\n",
      "[2024-03-30 21:33:41,798: INFO: model_logger: Epoch 386/1000, train_Loss: 7671.3759765625, val_Loss: 7258.8291]\n",
      "[2024-03-30 21:33:42,004: INFO: model_logger: Epoch 387/1000, train_Loss: 7639.484375, val_Loss: 7536.8848]\n",
      "[2024-03-30 21:33:42,289: INFO: model_logger: Epoch 388/1000, train_Loss: 7806.20751953125, val_Loss: 7454.4858]\n",
      "[2024-03-30 21:33:42,498: INFO: model_logger: Epoch 389/1000, train_Loss: 7757.9404296875, val_Loss: 7707.8213]\n",
      "[2024-03-30 21:33:42,706: INFO: model_logger: Epoch 390/1000, train_Loss: 7665.30859375, val_Loss: 7523.6836]\n",
      "[2024-03-30 21:33:42,972: INFO: model_logger: Epoch 391/1000, train_Loss: 7724.23388671875, val_Loss: 7604.0698]\n",
      "[2024-03-30 21:33:43,175: INFO: model_logger: Epoch 392/1000, train_Loss: 7717.97802734375, val_Loss: 7896.2695]\n",
      "[2024-03-30 21:33:43,377: INFO: model_logger: Epoch 393/1000, train_Loss: 7666.17333984375, val_Loss: 7495.5000]\n",
      "[2024-03-30 21:33:43,647: INFO: model_logger: Epoch 394/1000, train_Loss: 7888.7138671875, val_Loss: 7315.8008]\n",
      "[2024-03-30 21:33:43,871: INFO: model_logger: Epoch 395/1000, train_Loss: 7699.27490234375, val_Loss: 7599.5991]\n",
      "[2024-03-30 21:33:44,093: INFO: model_logger: Epoch 396/1000, train_Loss: 7727.890625, val_Loss: 7573.2148]\n",
      "[2024-03-30 21:33:44,368: INFO: model_logger: Epoch 397/1000, train_Loss: 7697.1435546875, val_Loss: 7643.0034]\n",
      "[2024-03-30 21:33:44,570: INFO: model_logger: Epoch 398/1000, train_Loss: 7826.7041015625, val_Loss: 7765.8076]\n",
      "[2024-03-30 21:33:44,776: INFO: model_logger: Epoch 399/1000, train_Loss: 7693.7216796875, val_Loss: 7986.0928]\n",
      "[2024-03-30 21:33:44,983: INFO: model_logger: Epoch 400/1000, train_Loss: 7898.25146484375, val_Loss: 7581.0723]\n",
      "[2024-03-30 21:33:45,248: INFO: model_logger: Epoch 401/1000, train_Loss: 7880.14599609375, val_Loss: 7764.4390]\n",
      "[2024-03-30 21:33:45,456: INFO: model_logger: Epoch 402/1000, train_Loss: 7816.56982421875, val_Loss: 7532.4272]\n",
      "[2024-03-30 21:33:45,659: INFO: model_logger: Epoch 403/1000, train_Loss: 7741.62890625, val_Loss: 7689.4800]\n",
      "[2024-03-30 21:33:45,927: INFO: model_logger: Epoch 404/1000, train_Loss: 7821.833984375, val_Loss: 7616.4102]\n",
      "[2024-03-30 21:33:46,136: INFO: model_logger: Epoch 405/1000, train_Loss: 7840.74951171875, val_Loss: 8015.9336]\n",
      "[2024-03-30 21:33:46,338: INFO: model_logger: Epoch 406/1000, train_Loss: 7788.37109375, val_Loss: 7791.8477]\n",
      "[2024-03-30 21:33:46,607: INFO: model_logger: Epoch 407/1000, train_Loss: 7795.91796875, val_Loss: 7351.6445]\n",
      "[2024-03-30 21:33:46,815: INFO: model_logger: Epoch 408/1000, train_Loss: 7808.96826171875, val_Loss: 7422.5889]\n",
      "[2024-03-30 21:33:47,075: INFO: model_logger: Epoch 409/1000, train_Loss: 7798.44775390625, val_Loss: 7845.3105]\n",
      "[2024-03-30 21:33:47,295: INFO: model_logger: Epoch 410/1000, train_Loss: 7726.5458984375, val_Loss: 7989.8398]\n",
      "[2024-03-30 21:33:47,571: INFO: model_logger: Epoch 411/1000, train_Loss: 7648.45751953125, val_Loss: 8045.9531]\n",
      "[2024-03-30 21:33:47,776: INFO: model_logger: Epoch 412/1000, train_Loss: 7781.2421875, val_Loss: 7910.2490]\n",
      "[2024-03-30 21:33:47,979: INFO: model_logger: Epoch 413/1000, train_Loss: 7762.8076171875, val_Loss: 7838.8486]\n",
      "[2024-03-30 21:33:48,265: INFO: model_logger: Epoch 414/1000, train_Loss: 7891.62451171875, val_Loss: 7693.0693]\n",
      "[2024-03-30 21:33:48,462: INFO: model_logger: Epoch 415/1000, train_Loss: 7763.08251953125, val_Loss: 7796.2495]\n",
      "[2024-03-30 21:33:48,662: INFO: model_logger: Epoch 416/1000, train_Loss: 7702.9521484375, val_Loss: 7740.7129]\n",
      "[2024-03-30 21:33:48,948: INFO: model_logger: Epoch 417/1000, train_Loss: 7692.82421875, val_Loss: 7550.6611]\n",
      "[2024-03-30 21:33:49,174: INFO: model_logger: Epoch 418/1000, train_Loss: 7763.4072265625, val_Loss: 7779.7202]\n",
      "[2024-03-30 21:33:49,388: INFO: model_logger: Epoch 419/1000, train_Loss: 7648.26025390625, val_Loss: 7497.3511]\n",
      "[2024-03-30 21:33:49,660: INFO: model_logger: Epoch 420/1000, train_Loss: 7834.2255859375, val_Loss: 7528.8662]\n",
      "[2024-03-30 21:33:49,869: INFO: model_logger: Epoch 421/1000, train_Loss: 7755.71826171875, val_Loss: 7817.3711]\n",
      "[2024-03-30 21:33:50,079: INFO: model_logger: Epoch 422/1000, train_Loss: 7700.48193359375, val_Loss: 7433.6982]\n",
      "[2024-03-30 21:33:50,295: INFO: model_logger: Epoch 423/1000, train_Loss: 7749.65283203125, val_Loss: 7759.2656]\n",
      "[2024-03-30 21:33:50,576: INFO: model_logger: Epoch 424/1000, train_Loss: 7836.93701171875, val_Loss: 7537.5991]\n",
      "[2024-03-30 21:33:50,788: INFO: model_logger: Epoch 425/1000, train_Loss: 7763.53125, val_Loss: 7355.8955]\n",
      "[2024-03-30 21:33:50,993: INFO: model_logger: Epoch 426/1000, train_Loss: 7817.59521484375, val_Loss: 7762.4365]\n",
      "[2024-03-30 21:33:51,273: INFO: model_logger: Epoch 427/1000, train_Loss: 7682.4013671875, val_Loss: 7537.5815]\n",
      "[2024-03-30 21:33:51,482: INFO: model_logger: Epoch 428/1000, train_Loss: 7790.05908203125, val_Loss: 7678.3296]\n",
      "[2024-03-30 21:33:51,694: INFO: model_logger: Epoch 429/1000, train_Loss: 7608.671875, val_Loss: 7603.0674]\n",
      "[2024-03-30 21:33:51,969: INFO: model_logger: Epoch 430/1000, train_Loss: 7901.65234375, val_Loss: 7352.8438]\n",
      "[2024-03-30 21:33:52,176: INFO: model_logger: Epoch 431/1000, train_Loss: 7701.3671875, val_Loss: 7500.5449]\n",
      "[2024-03-30 21:33:52,390: INFO: model_logger: Epoch 432/1000, train_Loss: 7783.4287109375, val_Loss: 7845.8433]\n",
      "[2024-03-30 21:33:52,596: INFO: model_logger: Epoch 433/1000, train_Loss: 7756.51318359375, val_Loss: 7694.6963]\n",
      "[2024-03-30 21:33:52,878: INFO: model_logger: Epoch 434/1000, train_Loss: 7744.78076171875, val_Loss: 7760.7598]\n",
      "[2024-03-30 21:33:53,085: INFO: model_logger: Epoch 435/1000, train_Loss: 7740.5869140625, val_Loss: 8039.6929]\n",
      "[2024-03-30 21:33:53,294: INFO: model_logger: Epoch 436/1000, train_Loss: 7795.0859375, val_Loss: 7977.2480]\n",
      "[2024-03-30 21:33:53,591: INFO: model_logger: Epoch 437/1000, train_Loss: 7775.30615234375, val_Loss: 8318.5410]\n",
      "[2024-03-30 21:33:53,805: INFO: model_logger: Epoch 438/1000, train_Loss: 7750.24462890625, val_Loss: 7609.0059]\n",
      "[2024-03-30 21:33:54,047: INFO: model_logger: Epoch 439/1000, train_Loss: 7679.60546875, val_Loss: 7634.3916]\n",
      "[2024-03-30 21:33:54,342: INFO: model_logger: Epoch 440/1000, train_Loss: 7664.685546875, val_Loss: 7307.0952]\n",
      "[2024-03-30 21:33:54,566: INFO: model_logger: Epoch 441/1000, train_Loss: 7701.36962890625, val_Loss: 7735.7617]\n",
      "[2024-03-30 21:33:54,778: INFO: model_logger: Epoch 442/1000, train_Loss: 7718.693359375, val_Loss: 8150.5210]\n",
      "[2024-03-30 21:33:55,084: INFO: model_logger: Epoch 443/1000, train_Loss: 7669.05224609375, val_Loss: 7406.0166]\n",
      "[2024-03-30 21:33:55,295: INFO: model_logger: Epoch 444/1000, train_Loss: 7802.74462890625, val_Loss: 7573.3799]\n",
      "[2024-03-30 21:33:55,527: INFO: model_logger: Epoch 445/1000, train_Loss: 7817.61328125, val_Loss: 7309.2920]\n",
      "[2024-03-30 21:33:55,793: INFO: model_logger: Epoch 446/1000, train_Loss: 7824.3935546875, val_Loss: 7890.8232]\n",
      "[2024-03-30 21:33:56,114: INFO: model_logger: Epoch 447/1000, train_Loss: 7800.88427734375, val_Loss: 7421.1133]\n",
      "[2024-03-30 21:33:56,341: INFO: model_logger: Epoch 448/1000, train_Loss: 7712.3994140625, val_Loss: 7545.5498]\n",
      "[2024-03-30 21:33:56,561: INFO: model_logger: Epoch 449/1000, train_Loss: 7688.1640625, val_Loss: 7494.2197]\n",
      "[2024-03-30 21:33:56,846: INFO: model_logger: Epoch 450/1000, train_Loss: 7696.1416015625, val_Loss: 7768.8506]\n",
      "[2024-03-30 21:33:57,143: INFO: model_logger: Epoch 451/1000, train_Loss: 7813.74169921875, val_Loss: 7665.6851]\n",
      "[2024-03-30 21:33:57,645: INFO: model_logger: Epoch 452/1000, train_Loss: 7704.34130859375, val_Loss: 7457.2476]\n",
      "[2024-03-30 21:33:58,319: INFO: model_logger: Epoch 453/1000, train_Loss: 7678.0849609375, val_Loss: 7713.8135]\n",
      "[2024-03-30 21:33:58,646: INFO: model_logger: Epoch 454/1000, train_Loss: 7941.53271484375, val_Loss: 7523.9468]\n",
      "[2024-03-30 21:33:58,915: INFO: model_logger: Epoch 455/1000, train_Loss: 7741.3310546875, val_Loss: 7794.0088]\n",
      "[2024-03-30 21:33:59,141: INFO: model_logger: Epoch 456/1000, train_Loss: 7738.8857421875, val_Loss: 7601.8564]\n",
      "[2024-03-30 21:33:59,422: INFO: model_logger: Epoch 457/1000, train_Loss: 7713.2333984375, val_Loss: 7374.9893]\n",
      "[2024-03-30 21:33:59,661: INFO: model_logger: Epoch 458/1000, train_Loss: 7772.50732421875, val_Loss: 7592.1494]\n",
      "[2024-03-30 21:33:59,880: INFO: model_logger: Epoch 459/1000, train_Loss: 7652.5146484375, val_Loss: 7578.3862]\n",
      "[2024-03-30 21:34:00,148: INFO: model_logger: Epoch 460/1000, train_Loss: 7692.0419921875, val_Loss: 8035.1182]\n",
      "[2024-03-30 21:34:00,341: INFO: model_logger: Epoch 461/1000, train_Loss: 7871.69140625, val_Loss: 7619.9272]\n",
      "[2024-03-30 21:34:00,543: INFO: model_logger: Epoch 462/1000, train_Loss: 7804.87890625, val_Loss: 7495.8901]\n",
      "[2024-03-30 21:34:00,809: INFO: model_logger: Epoch 463/1000, train_Loss: 7825.51220703125, val_Loss: 7752.6787]\n",
      "[2024-03-30 21:34:01,012: INFO: model_logger: Epoch 464/1000, train_Loss: 7781.12646484375, val_Loss: 7797.1050]\n",
      "[2024-03-30 21:34:01,202: INFO: model_logger: Epoch 465/1000, train_Loss: 7712.83349609375, val_Loss: 7643.8926]\n",
      "[2024-03-30 21:34:01,483: INFO: model_logger: Epoch 466/1000, train_Loss: 7773.45849609375, val_Loss: 7550.2437]\n",
      "[2024-03-30 21:34:01,704: INFO: model_logger: Epoch 467/1000, train_Loss: 7738.06640625, val_Loss: 7876.5718]\n",
      "[2024-03-30 21:34:01,942: INFO: model_logger: Epoch 468/1000, train_Loss: 7735.49365234375, val_Loss: 7785.4448]\n",
      "[2024-03-30 21:34:02,177: INFO: model_logger: Epoch 469/1000, train_Loss: 7763.68115234375, val_Loss: 7566.8486]\n",
      "[2024-03-30 21:34:02,466: INFO: model_logger: Epoch 470/1000, train_Loss: 7763.974609375, val_Loss: 7556.0469]\n",
      "[2024-03-30 21:34:02,684: INFO: model_logger: Epoch 471/1000, train_Loss: 7621.2763671875, val_Loss: 7603.4326]\n",
      "[2024-03-30 21:34:02,889: INFO: model_logger: Epoch 472/1000, train_Loss: 7616.87158203125, val_Loss: 7776.9883]\n",
      "[2024-03-30 21:34:03,165: INFO: model_logger: Epoch 473/1000, train_Loss: 7778.44970703125, val_Loss: 7630.3726]\n",
      "[2024-03-30 21:34:03,376: INFO: model_logger: Epoch 474/1000, train_Loss: 7665.875, val_Loss: 7700.4526]\n",
      "[2024-03-30 21:34:03,590: INFO: model_logger: Epoch 475/1000, train_Loss: 7718.08251953125, val_Loss: 7736.5527]\n",
      "[2024-03-30 21:34:03,869: INFO: model_logger: Epoch 476/1000, train_Loss: 7700.42578125, val_Loss: 7123.2534]\n",
      "[2024-03-30 21:34:04,093: INFO: model_logger: Epoch 477/1000, train_Loss: 7808.67138671875, val_Loss: 7493.2725]\n",
      "[2024-03-30 21:34:04,299: INFO: model_logger: Epoch 478/1000, train_Loss: 7589.07958984375, val_Loss: 7588.6553]\n",
      "[2024-03-30 21:34:04,491: INFO: model_logger: Epoch 479/1000, train_Loss: 7724.67333984375, val_Loss: 7480.0483]\n",
      "[2024-03-30 21:34:04,742: INFO: model_logger: Epoch 480/1000, train_Loss: 7786.4697265625, val_Loss: 7638.5352]\n",
      "[2024-03-30 21:34:04,931: INFO: model_logger: Epoch 481/1000, train_Loss: 7689.19775390625, val_Loss: 7989.3042]\n",
      "[2024-03-30 21:34:05,125: INFO: model_logger: Epoch 482/1000, train_Loss: 7570.97314453125, val_Loss: 7794.6538]\n",
      "[2024-03-30 21:34:05,392: INFO: model_logger: Epoch 483/1000, train_Loss: 7685.0703125, val_Loss: 7588.2617]\n",
      "[2024-03-30 21:34:05,590: INFO: model_logger: Epoch 484/1000, train_Loss: 7704.5732421875, val_Loss: 7513.9180]\n",
      "[2024-03-30 21:34:05,788: INFO: model_logger: Epoch 485/1000, train_Loss: 7718.43408203125, val_Loss: 7862.6289]\n",
      "[2024-03-30 21:34:06,039: INFO: model_logger: Epoch 486/1000, train_Loss: 7681.29052734375, val_Loss: 7846.9990]\n",
      "[2024-03-30 21:34:06,232: INFO: model_logger: Epoch 487/1000, train_Loss: 7630.81201171875, val_Loss: 7651.8359]\n",
      "[2024-03-30 21:34:06,450: INFO: model_logger: Epoch 488/1000, train_Loss: 7752.984375, val_Loss: 7782.5273]\n",
      "[2024-03-30 21:34:06,719: INFO: model_logger: Epoch 489/1000, train_Loss: 7707.36474609375, val_Loss: 7600.0444]\n",
      "[2024-03-30 21:34:06,958: INFO: model_logger: Epoch 490/1000, train_Loss: 7700.2646484375, val_Loss: 7604.4585]\n",
      "[2024-03-30 21:34:07,171: INFO: model_logger: Epoch 491/1000, train_Loss: 7662.86669921875, val_Loss: 7458.2402]\n",
      "[2024-03-30 21:34:07,396: INFO: model_logger: Epoch 492/1000, train_Loss: 7605.62451171875, val_Loss: 7642.6562]\n",
      "[2024-03-30 21:34:07,684: INFO: model_logger: Epoch 493/1000, train_Loss: 7642.546875, val_Loss: 7814.5498]\n",
      "[2024-03-30 21:34:07,898: INFO: model_logger: Epoch 494/1000, train_Loss: 7504.11328125, val_Loss: 7841.4937]\n",
      "[2024-03-30 21:34:08,105: INFO: model_logger: Epoch 495/1000, train_Loss: 7638.08349609375, val_Loss: 7624.2578]\n",
      "[2024-03-30 21:34:08,382: INFO: model_logger: Epoch 496/1000, train_Loss: 7914.62646484375, val_Loss: 7744.9580]\n",
      "[2024-03-30 21:34:08,608: INFO: model_logger: Epoch 497/1000, train_Loss: 7784.3193359375, val_Loss: 7875.9780]\n",
      "[2024-03-30 21:34:08,833: INFO: model_logger: Epoch 498/1000, train_Loss: 7625.53857421875, val_Loss: 7594.0215]\n",
      "[2024-03-30 21:34:09,136: INFO: model_logger: Epoch 499/1000, train_Loss: 7604.1591796875, val_Loss: 7556.8545]\n",
      "[2024-03-30 21:34:09,427: INFO: model_logger: Epoch 500/1000, train_Loss: 7732.9951171875, val_Loss: 7639.8218]\n",
      "[2024-03-30 21:34:09,651: INFO: model_logger: Epoch 501/1000, train_Loss: 7550.25390625, val_Loss: 7526.0527]\n",
      "[2024-03-30 21:34:09,891: INFO: model_logger: Epoch 502/1000, train_Loss: 7710.41064453125, val_Loss: 7891.7266]\n",
      "[2024-03-30 21:34:10,190: INFO: model_logger: Epoch 503/1000, train_Loss: 7704.5498046875, val_Loss: 7599.1499]\n",
      "[2024-03-30 21:34:10,433: INFO: model_logger: Epoch 504/1000, train_Loss: 7571.18212890625, val_Loss: 7710.1396]\n",
      "[2024-03-30 21:34:10,662: INFO: model_logger: Epoch 505/1000, train_Loss: 7647.9873046875, val_Loss: 7599.7832]\n",
      "[2024-03-30 21:34:10,973: INFO: model_logger: Epoch 506/1000, train_Loss: 7601.0400390625, val_Loss: 7470.6172]\n",
      "[2024-03-30 21:34:11,203: INFO: model_logger: Epoch 507/1000, train_Loss: 7664.73388671875, val_Loss: 7634.5156]\n",
      "[2024-03-30 21:34:11,417: INFO: model_logger: Epoch 508/1000, train_Loss: 7663.40087890625, val_Loss: 7501.6484]\n",
      "[2024-03-30 21:34:11,697: INFO: model_logger: Epoch 509/1000, train_Loss: 7659.4013671875, val_Loss: 7576.3389]\n",
      "[2024-03-30 21:34:11,910: INFO: model_logger: Epoch 510/1000, train_Loss: 7590.2666015625, val_Loss: 7675.5850]\n",
      "[2024-03-30 21:34:12,118: INFO: model_logger: Epoch 511/1000, train_Loss: 7600.54052734375, val_Loss: 7256.6221]\n",
      "[2024-03-30 21:34:12,408: INFO: model_logger: Epoch 512/1000, train_Loss: 7635.62158203125, val_Loss: 7886.4023]\n",
      "[2024-03-30 21:34:12,620: INFO: model_logger: Epoch 513/1000, train_Loss: 7924.4248046875, val_Loss: 7678.0581]\n",
      "[2024-03-30 21:34:12,836: INFO: model_logger: Epoch 514/1000, train_Loss: 7734.2333984375, val_Loss: 7634.5430]\n",
      "[2024-03-30 21:34:13,048: INFO: model_logger: Epoch 515/1000, train_Loss: 7634.5087890625, val_Loss: 7398.6929]\n",
      "[2024-03-30 21:34:13,332: INFO: model_logger: Epoch 516/1000, train_Loss: 7620.80126953125, val_Loss: 7677.6709]\n",
      "[2024-03-30 21:34:13,552: INFO: model_logger: Epoch 517/1000, train_Loss: 7753.23583984375, val_Loss: 7354.1191]\n",
      "[2024-03-30 21:34:13,766: INFO: model_logger: Epoch 518/1000, train_Loss: 7707.77734375, val_Loss: 7424.3691]\n",
      "[2024-03-30 21:34:14,092: INFO: model_logger: Epoch 519/1000, train_Loss: 7551.75244140625, val_Loss: 7526.2910]\n",
      "[2024-03-30 21:34:14,315: INFO: model_logger: Epoch 520/1000, train_Loss: 7745.54150390625, val_Loss: 7628.1729]\n",
      "[2024-03-30 21:34:14,538: INFO: model_logger: Epoch 521/1000, train_Loss: 7685.7529296875, val_Loss: 7648.9570]\n",
      "[2024-03-30 21:34:14,828: INFO: model_logger: Epoch 522/1000, train_Loss: 7623.81640625, val_Loss: 7357.4629]\n",
      "[2024-03-30 21:34:15,044: INFO: model_logger: Epoch 523/1000, train_Loss: 7814.607421875, val_Loss: 7595.5195]\n",
      "[2024-03-30 21:34:15,250: INFO: model_logger: Epoch 524/1000, train_Loss: 7666.13671875, val_Loss: 7501.1265]\n",
      "[2024-03-30 21:34:15,468: INFO: model_logger: Epoch 525/1000, train_Loss: 7663.63818359375, val_Loss: 7657.6812]\n",
      "[2024-03-30 21:34:15,747: INFO: model_logger: Epoch 526/1000, train_Loss: 7572.3994140625, val_Loss: 7662.8281]\n",
      "[2024-03-30 21:34:16,027: INFO: model_logger: Epoch 527/1000, train_Loss: 7852.58251953125, val_Loss: 7691.7124]\n",
      "[2024-03-30 21:34:16,257: INFO: model_logger: Epoch 528/1000, train_Loss: 7759.0791015625, val_Loss: 8049.5498]\n",
      "[2024-03-30 21:34:16,552: INFO: model_logger: Epoch 529/1000, train_Loss: 7762.33984375, val_Loss: 7388.2729]\n",
      "[2024-03-30 21:34:16,773: INFO: model_logger: Epoch 530/1000, train_Loss: 7780.5654296875, val_Loss: 7980.4897]\n",
      "[2024-03-30 21:34:16,985: INFO: model_logger: Epoch 531/1000, train_Loss: 7679.388671875, val_Loss: 7449.7710]\n",
      "[2024-03-30 21:34:17,288: INFO: model_logger: Epoch 532/1000, train_Loss: 7725.640625, val_Loss: 7736.8848]\n",
      "[2024-03-30 21:34:17,511: INFO: model_logger: Epoch 533/1000, train_Loss: 7834.83056640625, val_Loss: 7885.1904]\n",
      "[2024-03-30 21:34:17,739: INFO: model_logger: Epoch 534/1000, train_Loss: 7662.80419921875, val_Loss: 7687.1406]\n",
      "[2024-03-30 21:34:18,024: INFO: model_logger: Epoch 535/1000, train_Loss: 7605.04296875, val_Loss: 7849.0439]\n",
      "[2024-03-30 21:34:18,254: INFO: model_logger: Epoch 536/1000, train_Loss: 7727.71826171875, val_Loss: 7616.8672]\n",
      "[2024-03-30 21:34:18,496: INFO: model_logger: Epoch 537/1000, train_Loss: 7721.6474609375, val_Loss: 7690.7065]\n",
      "[2024-03-30 21:34:18,712: INFO: model_logger: Epoch 538/1000, train_Loss: 7677.2431640625, val_Loss: 7559.4502]\n",
      "[2024-03-30 21:34:19,036: INFO: model_logger: Epoch 539/1000, train_Loss: 7615.359375, val_Loss: 7695.7100]\n",
      "[2024-03-30 21:34:19,300: INFO: model_logger: Epoch 540/1000, train_Loss: 7610.18212890625, val_Loss: 7833.1187]\n",
      "[2024-03-30 21:34:19,523: INFO: model_logger: Epoch 541/1000, train_Loss: 7664.11962890625, val_Loss: 7713.7139]\n",
      "[2024-03-30 21:34:19,826: INFO: model_logger: Epoch 542/1000, train_Loss: 7599.5732421875, val_Loss: 7656.3291]\n",
      "[2024-03-30 21:34:20,048: INFO: model_logger: Epoch 543/1000, train_Loss: 7705.94140625, val_Loss: 7733.9585]\n",
      "[2024-03-30 21:34:20,279: INFO: model_logger: Epoch 544/1000, train_Loss: 7722.0380859375, val_Loss: 7468.9233]\n",
      "[2024-03-30 21:34:20,568: INFO: model_logger: Epoch 545/1000, train_Loss: 7672.25732421875, val_Loss: 7449.7734]\n",
      "[2024-03-30 21:34:20,780: INFO: model_logger: Epoch 546/1000, train_Loss: 7709.28125, val_Loss: 7869.0303]\n",
      "[2024-03-30 21:34:20,999: INFO: model_logger: Epoch 547/1000, train_Loss: 7819.16357421875, val_Loss: 7775.3271]\n",
      "[2024-03-30 21:34:21,216: INFO: model_logger: Epoch 548/1000, train_Loss: 7709.49658203125, val_Loss: 7572.9639]\n",
      "[2024-03-30 21:34:21,520: INFO: model_logger: Epoch 549/1000, train_Loss: 7649.18896484375, val_Loss: 7675.1660]\n",
      "[2024-03-30 21:34:21,739: INFO: model_logger: Epoch 550/1000, train_Loss: 7619.810546875, val_Loss: 7402.9004]\n",
      "[2024-03-30 21:34:21,951: INFO: model_logger: Epoch 551/1000, train_Loss: 7671.59033203125, val_Loss: 7607.2646]\n",
      "[2024-03-30 21:34:22,226: INFO: model_logger: Epoch 552/1000, train_Loss: 7825.9697265625, val_Loss: 7258.3394]\n",
      "[2024-03-30 21:34:22,449: INFO: model_logger: Epoch 553/1000, train_Loss: 7623.4375, val_Loss: 7487.6323]\n",
      "[2024-03-30 21:34:22,715: INFO: model_logger: Epoch 554/1000, train_Loss: 7773.49755859375, val_Loss: 7612.5010]\n",
      "[2024-03-30 21:34:23,010: INFO: model_logger: Epoch 555/1000, train_Loss: 7636.15380859375, val_Loss: 7495.3633]\n",
      "[2024-03-30 21:34:23,247: INFO: model_logger: Epoch 556/1000, train_Loss: 7542.66943359375, val_Loss: 7801.1670]\n",
      "[2024-03-30 21:34:23,494: INFO: model_logger: Epoch 557/1000, train_Loss: 7692.32470703125, val_Loss: 7828.4141]\n",
      "[2024-03-30 21:34:23,774: INFO: model_logger: Epoch 558/1000, train_Loss: 7751.09326171875, val_Loss: 7669.3999]\n",
      "[2024-03-30 21:34:24,011: INFO: model_logger: Epoch 559/1000, train_Loss: 7715.3740234375, val_Loss: 7604.8022]\n",
      "[2024-03-30 21:34:24,288: INFO: model_logger: Epoch 560/1000, train_Loss: 7677.9140625, val_Loss: 7707.8926]\n",
      "[2024-03-30 21:34:24,508: INFO: model_logger: Epoch 561/1000, train_Loss: 7765.78515625, val_Loss: 7914.8037]\n",
      "[2024-03-30 21:34:24,794: INFO: model_logger: Epoch 562/1000, train_Loss: 7672.6484375, val_Loss: 7671.8296]\n",
      "[2024-03-30 21:34:25,002: INFO: model_logger: Epoch 563/1000, train_Loss: 7634.74658203125, val_Loss: 7815.8955]\n",
      "[2024-03-30 21:34:25,209: INFO: model_logger: Epoch 564/1000, train_Loss: 7814.51025390625, val_Loss: 7871.9287]\n",
      "[2024-03-30 21:34:25,491: INFO: model_logger: Epoch 565/1000, train_Loss: 7583.9990234375, val_Loss: 7785.3096]\n",
      "[2024-03-30 21:34:25,703: INFO: model_logger: Epoch 566/1000, train_Loss: 7754.7724609375, val_Loss: 7610.8882]\n",
      "[2024-03-30 21:34:25,919: INFO: model_logger: Epoch 567/1000, train_Loss: 7664.40576171875, val_Loss: 7589.8296]\n",
      "[2024-03-30 21:34:26,197: INFO: model_logger: Epoch 568/1000, train_Loss: 7823.576171875, val_Loss: 7355.9648]\n",
      "[2024-03-30 21:34:26,410: INFO: model_logger: Epoch 569/1000, train_Loss: 7733.29150390625, val_Loss: 7539.6787]\n",
      "[2024-03-30 21:34:26,629: INFO: model_logger: Epoch 570/1000, train_Loss: 7607.7119140625, val_Loss: 7930.8457]\n",
      "[2024-03-30 21:34:26,843: INFO: model_logger: Epoch 571/1000, train_Loss: 7599.2900390625, val_Loss: 8020.6851]\n",
      "[2024-03-30 21:34:27,143: INFO: model_logger: Epoch 572/1000, train_Loss: 7562.84814453125, val_Loss: 7691.5225]\n",
      "[2024-03-30 21:34:27,363: INFO: model_logger: Epoch 573/1000, train_Loss: 7817.0478515625, val_Loss: 7541.1768]\n",
      "[2024-03-30 21:34:27,623: INFO: model_logger: Epoch 574/1000, train_Loss: 7732.921875, val_Loss: 7902.8452]\n",
      "[2024-03-30 21:34:27,918: INFO: model_logger: Epoch 575/1000, train_Loss: 7745.78662109375, val_Loss: 7722.2749]\n",
      "[2024-03-30 21:34:28,148: INFO: model_logger: Epoch 576/1000, train_Loss: 7682.2744140625, val_Loss: 7603.4897]\n",
      "[2024-03-30 21:34:28,360: INFO: model_logger: Epoch 577/1000, train_Loss: 7683.8681640625, val_Loss: 7554.8740]\n",
      "[2024-03-30 21:34:28,656: INFO: model_logger: Epoch 578/1000, train_Loss: 7711.86083984375, val_Loss: 7575.4170]\n",
      "[2024-03-30 21:34:28,884: INFO: model_logger: Epoch 579/1000, train_Loss: 7884.982421875, val_Loss: 7775.4487]\n",
      "[2024-03-30 21:34:29,157: INFO: model_logger: Epoch 580/1000, train_Loss: 7692.86083984375, val_Loss: 7475.2163]\n",
      "[2024-03-30 21:34:29,456: INFO: model_logger: Epoch 581/1000, train_Loss: 7800.7333984375, val_Loss: 7516.8887]\n",
      "[2024-03-30 21:34:29,677: INFO: model_logger: Epoch 582/1000, train_Loss: 7645.6123046875, val_Loss: 7992.9678]\n",
      "[2024-03-30 21:34:29,912: INFO: model_logger: Epoch 583/1000, train_Loss: 7731.68212890625, val_Loss: 7804.6377]\n",
      "[2024-03-30 21:34:30,142: INFO: model_logger: Epoch 584/1000, train_Loss: 7703.43896484375, val_Loss: 7927.9116]\n",
      "[2024-03-30 21:34:30,440: INFO: model_logger: Epoch 585/1000, train_Loss: 7846.84375, val_Loss: 7726.7319]\n",
      "[2024-03-30 21:34:30,667: INFO: model_logger: Epoch 586/1000, train_Loss: 7628.76806640625, val_Loss: 7669.2461]\n",
      "[2024-03-30 21:34:30,879: INFO: model_logger: Epoch 587/1000, train_Loss: 7596.294921875, val_Loss: 7377.5615]\n",
      "[2024-03-30 21:34:31,155: INFO: model_logger: Epoch 588/1000, train_Loss: 7724.6201171875, val_Loss: 7581.2549]\n",
      "[2024-03-30 21:34:31,382: INFO: model_logger: Epoch 589/1000, train_Loss: 7496.21240234375, val_Loss: 7499.1558]\n",
      "[2024-03-30 21:34:31,621: INFO: model_logger: Epoch 590/1000, train_Loss: 7730.0712890625, val_Loss: 7871.6680]\n",
      "[2024-03-30 21:34:31,917: INFO: model_logger: Epoch 591/1000, train_Loss: 7681.08544921875, val_Loss: 7550.8838]\n",
      "[2024-03-30 21:34:32,140: INFO: model_logger: Epoch 592/1000, train_Loss: 7724.1796875, val_Loss: 7777.0537]\n",
      "[2024-03-30 21:34:32,351: INFO: model_logger: Epoch 593/1000, train_Loss: 7805.43359375, val_Loss: 7452.4883]\n",
      "[2024-03-30 21:34:32,564: INFO: model_logger: Epoch 594/1000, train_Loss: 7606.21875, val_Loss: 7964.3555]\n",
      "[2024-03-30 21:34:32,847: INFO: model_logger: Epoch 595/1000, train_Loss: 7626.36865234375, val_Loss: 7350.3057]\n",
      "[2024-03-30 21:34:33,060: INFO: model_logger: Epoch 596/1000, train_Loss: 7721.04931640625, val_Loss: 7584.1611]\n",
      "[2024-03-30 21:34:33,267: INFO: model_logger: Epoch 597/1000, train_Loss: 7552.3740234375, val_Loss: 7518.2471]\n",
      "[2024-03-30 21:34:33,550: INFO: model_logger: Epoch 598/1000, train_Loss: 7804.224609375, val_Loss: 7783.4180]\n",
      "[2024-03-30 21:34:33,791: INFO: model_logger: Epoch 599/1000, train_Loss: 7615.50439453125, val_Loss: 7627.1523]\n",
      "[2024-03-30 21:34:34,076: INFO: model_logger: Epoch 600/1000, train_Loss: 7710.59130859375, val_Loss: 7809.3789]\n",
      "[2024-03-30 21:34:34,386: INFO: model_logger: Epoch 601/1000, train_Loss: 7605.8037109375, val_Loss: 7902.3027]\n",
      "[2024-03-30 21:34:34,674: INFO: model_logger: Epoch 602/1000, train_Loss: 7710.388671875, val_Loss: 7656.5132]\n",
      "[2024-03-30 21:34:34,917: INFO: model_logger: Epoch 603/1000, train_Loss: 7615.4072265625, val_Loss: 7942.6113]\n",
      "[2024-03-30 21:34:35,204: INFO: model_logger: Epoch 604/1000, train_Loss: 7595.0224609375, val_Loss: 7679.4639]\n",
      "[2024-03-30 21:34:35,418: INFO: model_logger: Epoch 605/1000, train_Loss: 7558.33740234375, val_Loss: 7724.8076]\n",
      "[2024-03-30 21:34:35,642: INFO: model_logger: Epoch 606/1000, train_Loss: 7620.15380859375, val_Loss: 7460.5874]\n",
      "[2024-03-30 21:34:35,856: INFO: model_logger: Epoch 607/1000, train_Loss: 7525.58740234375, val_Loss: 7733.5850]\n",
      "[2024-03-30 21:34:36,133: INFO: model_logger: Epoch 608/1000, train_Loss: 7719.83251953125, val_Loss: 7565.1484]\n",
      "[2024-03-30 21:34:36,343: INFO: model_logger: Epoch 609/1000, train_Loss: 7599.6962890625, val_Loss: 7668.8076]\n",
      "[2024-03-30 21:34:36,556: INFO: model_logger: Epoch 610/1000, train_Loss: 7534.388671875, val_Loss: 7512.7695]\n",
      "[2024-03-30 21:34:36,839: INFO: model_logger: Epoch 611/1000, train_Loss: 7574.2841796875, val_Loss: 7390.6929]\n",
      "[2024-03-30 21:34:37,049: INFO: model_logger: Epoch 612/1000, train_Loss: 7647.12255859375, val_Loss: 7431.2383]\n",
      "[2024-03-30 21:34:37,263: INFO: model_logger: Epoch 613/1000, train_Loss: 7633.2509765625, val_Loss: 7165.7783]\n",
      "[2024-03-30 21:34:37,540: INFO: model_logger: Epoch 614/1000, train_Loss: 7813.44921875, val_Loss: 7587.4521]\n",
      "[2024-03-30 21:34:37,765: INFO: model_logger: Epoch 615/1000, train_Loss: 7571.86474609375, val_Loss: 7328.6826]\n",
      "[2024-03-30 21:34:37,969: INFO: model_logger: Epoch 616/1000, train_Loss: 7745.6826171875, val_Loss: 7399.0195]\n",
      "[2024-03-30 21:34:38,184: INFO: model_logger: Epoch 617/1000, train_Loss: 7603.36328125, val_Loss: 7693.4590]\n",
      "[2024-03-30 21:34:38,459: INFO: model_logger: Epoch 618/1000, train_Loss: 7678.5419921875, val_Loss: 7303.3472]\n",
      "[2024-03-30 21:34:38,670: INFO: model_logger: Epoch 619/1000, train_Loss: 7530.8349609375, val_Loss: 7751.5693]\n",
      "[2024-03-30 21:34:38,896: INFO: model_logger: Epoch 620/1000, train_Loss: 7717.66796875, val_Loss: 7752.3662]\n",
      "[2024-03-30 21:34:39,191: INFO: model_logger: Epoch 621/1000, train_Loss: 7804.6943359375, val_Loss: 7623.1230]\n",
      "[2024-03-30 21:34:39,407: INFO: model_logger: Epoch 622/1000, train_Loss: 7619.71826171875, val_Loss: 7729.9531]\n",
      "[2024-03-30 21:34:39,621: INFO: model_logger: Epoch 623/1000, train_Loss: 7691.35888671875, val_Loss: 7615.9390]\n",
      "[2024-03-30 21:34:39,905: INFO: model_logger: Epoch 624/1000, train_Loss: 7589.69287109375, val_Loss: 7628.2324]\n",
      "[2024-03-30 21:34:40,113: INFO: model_logger: Epoch 625/1000, train_Loss: 7680.96826171875, val_Loss: 7612.8022]\n",
      "[2024-03-30 21:34:40,325: INFO: model_logger: Epoch 626/1000, train_Loss: 7638.96630859375, val_Loss: 7484.7480]\n",
      "[2024-03-30 21:34:40,593: INFO: model_logger: Epoch 627/1000, train_Loss: 7633.59912109375, val_Loss: 7705.0586]\n",
      "[2024-03-30 21:34:40,791: INFO: model_logger: Epoch 628/1000, train_Loss: 7670.5849609375, val_Loss: 7525.9912]\n",
      "[2024-03-30 21:34:41,004: INFO: model_logger: Epoch 629/1000, train_Loss: 7696.08984375, val_Loss: 7512.6069]\n",
      "[2024-03-30 21:34:41,205: INFO: model_logger: Epoch 630/1000, train_Loss: 7548.81005859375, val_Loss: 8013.3335]\n",
      "[2024-03-30 21:34:41,467: INFO: model_logger: Epoch 631/1000, train_Loss: 7604.53515625, val_Loss: 7884.3945]\n",
      "[2024-03-30 21:34:41,668: INFO: model_logger: Epoch 632/1000, train_Loss: 7539.30419921875, val_Loss: 7460.7754]\n",
      "[2024-03-30 21:34:41,871: INFO: model_logger: Epoch 633/1000, train_Loss: 7741.0693359375, val_Loss: 7615.2217]\n",
      "[2024-03-30 21:34:42,140: INFO: model_logger: Epoch 634/1000, train_Loss: 7657.81494140625, val_Loss: 7648.0420]\n",
      "[2024-03-30 21:34:42,339: INFO: model_logger: Epoch 635/1000, train_Loss: 7525.68701171875, val_Loss: 7714.7324]\n",
      "[2024-03-30 21:34:42,548: INFO: model_logger: Epoch 636/1000, train_Loss: 7661.4130859375, val_Loss: 7622.7529]\n",
      "[2024-03-30 21:34:42,824: INFO: model_logger: Epoch 637/1000, train_Loss: 7723.7177734375, val_Loss: 7637.5127]\n",
      "[2024-03-30 21:34:43,020: INFO: model_logger: Epoch 638/1000, train_Loss: 7633.30859375, val_Loss: 7369.5151]\n",
      "[2024-03-30 21:34:43,222: INFO: model_logger: Epoch 639/1000, train_Loss: 7516.94287109375, val_Loss: 7441.0327]\n",
      "[2024-03-30 21:34:43,418: INFO: model_logger: Epoch 640/1000, train_Loss: 7540.9619140625, val_Loss: 7620.8530]\n",
      "[2024-03-30 21:34:43,681: INFO: model_logger: Epoch 641/1000, train_Loss: 7612.03662109375, val_Loss: 7574.0762]\n",
      "[2024-03-30 21:34:43,887: INFO: model_logger: Epoch 642/1000, train_Loss: 7656.1416015625, val_Loss: 7606.0352]\n",
      "[2024-03-30 21:34:44,111: INFO: model_logger: Epoch 643/1000, train_Loss: 7606.0478515625, val_Loss: 7499.8975]\n",
      "[2024-03-30 21:34:44,385: INFO: model_logger: Epoch 644/1000, train_Loss: 7618.85888671875, val_Loss: 7482.5283]\n",
      "[2024-03-30 21:34:44,587: INFO: model_logger: Epoch 645/1000, train_Loss: 7644.71875, val_Loss: 7682.7456]\n",
      "[2024-03-30 21:34:44,788: INFO: model_logger: Epoch 646/1000, train_Loss: 7647.654296875, val_Loss: 7586.1968]\n",
      "[2024-03-30 21:34:45,048: INFO: model_logger: Epoch 647/1000, train_Loss: 7559.193359375, val_Loss: 7582.3721]\n",
      "[2024-03-30 21:34:45,252: INFO: model_logger: Epoch 648/1000, train_Loss: 7724.28564453125, val_Loss: 7770.5366]\n",
      "[2024-03-30 21:34:45,456: INFO: model_logger: Epoch 649/1000, train_Loss: 7705.25244140625, val_Loss: 7556.6680]\n",
      "[2024-03-30 21:34:45,721: INFO: model_logger: Epoch 650/1000, train_Loss: 7673.6982421875, val_Loss: 7600.7529]\n",
      "[2024-03-30 21:34:45,923: INFO: model_logger: Epoch 651/1000, train_Loss: 7741.12939453125, val_Loss: 7606.8623]\n",
      "[2024-03-30 21:34:46,121: INFO: model_logger: Epoch 652/1000, train_Loss: 7624.12255859375, val_Loss: 7812.3477]\n",
      "[2024-03-30 21:34:46,341: INFO: model_logger: Epoch 653/1000, train_Loss: 7535.05908203125, val_Loss: 7563.5264]\n",
      "[2024-03-30 21:34:46,614: INFO: model_logger: Epoch 654/1000, train_Loss: 7567.58349609375, val_Loss: 7295.8701]\n",
      "[2024-03-30 21:34:46,814: INFO: model_logger: Epoch 655/1000, train_Loss: 7743.904296875, val_Loss: 7737.1011]\n",
      "[2024-03-30 21:34:47,014: INFO: model_logger: Epoch 656/1000, train_Loss: 7567.49609375, val_Loss: 7713.1792]\n",
      "[2024-03-30 21:34:47,276: INFO: model_logger: Epoch 657/1000, train_Loss: 7619.35302734375, val_Loss: 7659.2412]\n",
      "[2024-03-30 21:34:47,476: INFO: model_logger: Epoch 658/1000, train_Loss: 7517.78662109375, val_Loss: 7672.5781]\n",
      "[2024-03-30 21:34:47,677: INFO: model_logger: Epoch 659/1000, train_Loss: 7632.00927734375, val_Loss: 8124.6914]\n",
      "[2024-03-30 21:34:47,939: INFO: model_logger: Epoch 660/1000, train_Loss: 7706.365234375, val_Loss: 7610.6758]\n",
      "[2024-03-30 21:34:48,138: INFO: model_logger: Epoch 661/1000, train_Loss: 7602.3662109375, val_Loss: 7677.7676]\n",
      "[2024-03-30 21:34:48,334: INFO: model_logger: Epoch 662/1000, train_Loss: 7641.7177734375, val_Loss: 7725.9844]\n",
      "[2024-03-30 21:34:48,542: INFO: model_logger: Epoch 663/1000, train_Loss: 7566.27490234375, val_Loss: 7577.7314]\n",
      "[2024-03-30 21:34:48,808: INFO: model_logger: Epoch 664/1000, train_Loss: 7510.97119140625, val_Loss: 8016.2666]\n",
      "[2024-03-30 21:34:49,082: INFO: model_logger: Epoch 665/1000, train_Loss: 7628.8544921875, val_Loss: 7651.5601]\n",
      "[2024-03-30 21:34:49,296: INFO: model_logger: Epoch 666/1000, train_Loss: 7578.9150390625, val_Loss: 7742.2881]\n",
      "[2024-03-30 21:34:49,568: INFO: model_logger: Epoch 667/1000, train_Loss: 7746.365234375, val_Loss: 7967.8867]\n",
      "[2024-03-30 21:34:49,771: INFO: model_logger: Epoch 668/1000, train_Loss: 7654.9951171875, val_Loss: 7565.4531]\n",
      "[2024-03-30 21:34:49,967: INFO: model_logger: Epoch 669/1000, train_Loss: 7631.2119140625, val_Loss: 7578.8477]\n",
      "[2024-03-30 21:34:50,230: INFO: model_logger: Epoch 670/1000, train_Loss: 7689.18994140625, val_Loss: 7916.3350]\n",
      "[2024-03-30 21:34:50,425: INFO: model_logger: Epoch 671/1000, train_Loss: 7700.08837890625, val_Loss: 7817.4238]\n",
      "[2024-03-30 21:34:50,634: INFO: model_logger: Epoch 672/1000, train_Loss: 7540.26220703125, val_Loss: 7413.3682]\n",
      "[2024-03-30 21:34:50,893: INFO: model_logger: Epoch 673/1000, train_Loss: 7588.76220703125, val_Loss: 7635.6406]\n",
      "[2024-03-30 21:34:51,091: INFO: model_logger: Epoch 674/1000, train_Loss: 7606.9794921875, val_Loss: 7593.6543]\n",
      "[2024-03-30 21:34:51,291: INFO: model_logger: Epoch 675/1000, train_Loss: 7618.953125, val_Loss: 7772.6133]\n",
      "[2024-03-30 21:34:51,489: INFO: model_logger: Epoch 676/1000, train_Loss: 7465.5947265625, val_Loss: 7719.0132]\n",
      "[2024-03-30 21:34:51,772: INFO: model_logger: Epoch 677/1000, train_Loss: 7589.669921875, val_Loss: 7919.2959]\n",
      "[2024-03-30 21:34:51,967: INFO: model_logger: Epoch 678/1000, train_Loss: 7667.65380859375, val_Loss: 7471.4570]\n",
      "[2024-03-30 21:34:52,162: INFO: model_logger: Epoch 679/1000, train_Loss: 7662.732421875, val_Loss: 7325.6772]\n",
      "[2024-03-30 21:34:52,422: INFO: model_logger: Epoch 680/1000, train_Loss: 7633.521484375, val_Loss: 7494.2007]\n",
      "[2024-03-30 21:34:52,622: INFO: model_logger: Epoch 681/1000, train_Loss: 7615.00537109375, val_Loss: 7670.5835]\n",
      "[2024-03-30 21:34:52,830: INFO: model_logger: Epoch 682/1000, train_Loss: 7682.16064453125, val_Loss: 7696.5503]\n",
      "[2024-03-30 21:34:53,086: INFO: model_logger: Epoch 683/1000, train_Loss: 7564.8671875, val_Loss: 7586.4131]\n",
      "[2024-03-30 21:34:53,287: INFO: model_logger: Epoch 684/1000, train_Loss: 7573.43115234375, val_Loss: 7868.8906]\n",
      "[2024-03-30 21:34:53,487: INFO: model_logger: Epoch 685/1000, train_Loss: 7598.57958984375, val_Loss: 7571.9854]\n",
      "[2024-03-30 21:34:53,689: INFO: model_logger: Epoch 686/1000, train_Loss: 7628.52001953125, val_Loss: 7718.8447]\n",
      "[2024-03-30 21:34:53,968: INFO: model_logger: Epoch 687/1000, train_Loss: 7549.0, val_Loss: 8101.2847]\n",
      "[2024-03-30 21:34:54,179: INFO: model_logger: Epoch 688/1000, train_Loss: 7643.62451171875, val_Loss: 7439.2188]\n",
      "[2024-03-30 21:34:54,380: INFO: model_logger: Epoch 689/1000, train_Loss: 7730.26220703125, val_Loss: 7934.8691]\n",
      "[2024-03-30 21:34:54,643: INFO: model_logger: Epoch 690/1000, train_Loss: 7516.6005859375, val_Loss: 7593.9609]\n",
      "[2024-03-30 21:34:54,845: INFO: model_logger: Epoch 691/1000, train_Loss: 7561.388671875, val_Loss: 7921.5229]\n",
      "[2024-03-30 21:34:55,043: INFO: model_logger: Epoch 692/1000, train_Loss: 7719.7607421875, val_Loss: 7405.6245]\n",
      "[2024-03-30 21:34:55,306: INFO: model_logger: Epoch 693/1000, train_Loss: 7594.2373046875, val_Loss: 7915.0840]\n",
      "[2024-03-30 21:34:55,507: INFO: model_logger: Epoch 694/1000, train_Loss: 7735.7529296875, val_Loss: 7485.5186]\n",
      "[2024-03-30 21:34:55,708: INFO: model_logger: Epoch 695/1000, train_Loss: 7599.435546875, val_Loss: 7469.2578]\n",
      "[2024-03-30 21:34:55,973: INFO: model_logger: Epoch 696/1000, train_Loss: 7551.82470703125, val_Loss: 7760.7983]\n",
      "[2024-03-30 21:34:56,171: INFO: model_logger: Epoch 697/1000, train_Loss: 7447.7216796875, val_Loss: 7604.0557]\n",
      "[2024-03-30 21:34:56,371: INFO: model_logger: Epoch 698/1000, train_Loss: 7929.3505859375, val_Loss: 7295.0381]\n",
      "[2024-03-30 21:34:56,580: INFO: model_logger: Epoch 699/1000, train_Loss: 7603.83251953125, val_Loss: 7794.0073]\n",
      "[2024-03-30 21:34:56,897: INFO: model_logger: Epoch 700/1000, train_Loss: 7703.796875, val_Loss: 7890.5547]\n",
      "[2024-03-30 21:34:57,129: INFO: model_logger: Epoch 701/1000, train_Loss: 7648.50927734375, val_Loss: 7649.0068]\n",
      "[2024-03-30 21:34:57,344: INFO: model_logger: Epoch 702/1000, train_Loss: 7603.94287109375, val_Loss: 7476.8276]\n",
      "[2024-03-30 21:34:57,654: INFO: model_logger: Epoch 703/1000, train_Loss: 7645.474609375, val_Loss: 7369.8086]\n",
      "[2024-03-30 21:34:57,865: INFO: model_logger: Epoch 704/1000, train_Loss: 7668.55126953125, val_Loss: 7678.0400]\n",
      "[2024-03-30 21:34:58,089: INFO: model_logger: Epoch 705/1000, train_Loss: 7746.20556640625, val_Loss: 7332.1309]\n",
      "[2024-03-30 21:34:58,364: INFO: model_logger: Epoch 706/1000, train_Loss: 7480.7587890625, val_Loss: 7799.9351]\n",
      "[2024-03-30 21:34:58,572: INFO: model_logger: Epoch 707/1000, train_Loss: 7576.18896484375, val_Loss: 7712.1426]\n",
      "[2024-03-30 21:34:58,789: INFO: model_logger: Epoch 708/1000, train_Loss: 7384.40771484375, val_Loss: 7668.7476]\n",
      "[2024-03-30 21:34:59,043: INFO: model_logger: Epoch 709/1000, train_Loss: 7520.76708984375, val_Loss: 7670.9526]\n",
      "[2024-03-30 21:34:59,382: INFO: model_logger: Epoch 710/1000, train_Loss: 7547.45458984375, val_Loss: 7888.9209]\n",
      "[2024-03-30 21:34:59,592: INFO: model_logger: Epoch 711/1000, train_Loss: 7730.60693359375, val_Loss: 7721.7031]\n",
      "[2024-03-30 21:34:59,827: INFO: model_logger: Epoch 712/1000, train_Loss: 7546.76171875, val_Loss: 7757.9443]\n",
      "[2024-03-30 21:35:00,120: INFO: model_logger: Epoch 713/1000, train_Loss: 7669.9326171875, val_Loss: 7668.7749]\n",
      "[2024-03-30 21:35:00,330: INFO: model_logger: Epoch 714/1000, train_Loss: 7578.5810546875, val_Loss: 7618.8555]\n",
      "[2024-03-30 21:35:00,540: INFO: model_logger: Epoch 715/1000, train_Loss: 7756.26220703125, val_Loss: 7640.8447]\n",
      "[2024-03-30 21:35:00,814: INFO: model_logger: Epoch 716/1000, train_Loss: 7603.30859375, val_Loss: 7568.6992]\n",
      "[2024-03-30 21:35:01,009: INFO: model_logger: Epoch 717/1000, train_Loss: 7521.39208984375, val_Loss: 7525.8652]\n",
      "[2024-03-30 21:35:01,215: INFO: model_logger: Epoch 718/1000, train_Loss: 7502.27001953125, val_Loss: 7580.4062]\n",
      "[2024-03-30 21:35:01,487: INFO: model_logger: Epoch 719/1000, train_Loss: 7587.8359375, val_Loss: 7232.8975]\n",
      "[2024-03-30 21:35:01,688: INFO: model_logger: Epoch 720/1000, train_Loss: 7663.69189453125, val_Loss: 7932.8999]\n",
      "[2024-03-30 21:35:01,899: INFO: model_logger: Epoch 721/1000, train_Loss: 7621.568359375, val_Loss: 7338.5898]\n",
      "[2024-03-30 21:35:02,094: INFO: model_logger: Epoch 722/1000, train_Loss: 7615.79931640625, val_Loss: 7636.1499]\n",
      "[2024-03-30 21:35:02,355: INFO: model_logger: Epoch 723/1000, train_Loss: 7634.60107421875, val_Loss: 7701.8535]\n",
      "[2024-03-30 21:35:02,558: INFO: model_logger: Epoch 724/1000, train_Loss: 7521.90625, val_Loss: 7667.1602]\n",
      "[2024-03-30 21:35:02,760: INFO: model_logger: Epoch 725/1000, train_Loss: 7567.1318359375, val_Loss: 7667.7236]\n",
      "[2024-03-30 21:35:03,020: INFO: model_logger: Epoch 726/1000, train_Loss: 7598.34375, val_Loss: 7679.1870]\n",
      "[2024-03-30 21:35:03,214: INFO: model_logger: Epoch 727/1000, train_Loss: 7695.4150390625, val_Loss: 7900.2417]\n",
      "[2024-03-30 21:35:03,420: INFO: model_logger: Epoch 728/1000, train_Loss: 7554.240234375, val_Loss: 7646.3413]\n",
      "[2024-03-30 21:35:03,685: INFO: model_logger: Epoch 729/1000, train_Loss: 7681.1962890625, val_Loss: 7600.7554]\n",
      "[2024-03-30 21:35:03,897: INFO: model_logger: Epoch 730/1000, train_Loss: 7639.7958984375, val_Loss: 7418.6777]\n",
      "[2024-03-30 21:35:04,115: INFO: model_logger: Epoch 731/1000, train_Loss: 7556.40283203125, val_Loss: 7383.1406]\n",
      "[2024-03-30 21:35:04,322: INFO: model_logger: Epoch 732/1000, train_Loss: 7577.14013671875, val_Loss: 7506.3711]\n",
      "[2024-03-30 21:35:04,588: INFO: model_logger: Epoch 733/1000, train_Loss: 7622.5712890625, val_Loss: 7689.5566]\n",
      "[2024-03-30 21:35:04,795: INFO: model_logger: Epoch 734/1000, train_Loss: 7637.287109375, val_Loss: 7522.7686]\n",
      "[2024-03-30 21:35:04,996: INFO: model_logger: Epoch 735/1000, train_Loss: 7632.2587890625, val_Loss: 7283.7178]\n",
      "[2024-03-30 21:35:05,257: INFO: model_logger: Epoch 736/1000, train_Loss: 7613.3623046875, val_Loss: 7875.2593]\n",
      "[2024-03-30 21:35:05,456: INFO: model_logger: Epoch 737/1000, train_Loss: 7576.7568359375, val_Loss: 7499.6592]\n",
      "[2024-03-30 21:35:05,663: INFO: model_logger: Epoch 738/1000, train_Loss: 7762.41357421875, val_Loss: 7794.1113]\n",
      "[2024-03-30 21:35:05,928: INFO: model_logger: Epoch 739/1000, train_Loss: 7691.5498046875, val_Loss: 7776.1719]\n",
      "[2024-03-30 21:35:06,127: INFO: model_logger: Epoch 740/1000, train_Loss: 7535.9228515625, val_Loss: 7487.3999]\n",
      "[2024-03-30 21:35:06,327: INFO: model_logger: Epoch 741/1000, train_Loss: 7722.32470703125, val_Loss: 7676.2100]\n",
      "[2024-03-30 21:35:06,596: INFO: model_logger: Epoch 742/1000, train_Loss: 7516.2802734375, val_Loss: 7606.4375]\n",
      "[2024-03-30 21:35:06,797: INFO: model_logger: Epoch 743/1000, train_Loss: 7524.193359375, val_Loss: 7637.3174]\n",
      "[2024-03-30 21:35:06,996: INFO: model_logger: Epoch 744/1000, train_Loss: 7520.58984375, val_Loss: 7582.6836]\n",
      "[2024-03-30 21:35:07,195: INFO: model_logger: Epoch 745/1000, train_Loss: 7580.2060546875, val_Loss: 7801.7705]\n",
      "[2024-03-30 21:35:07,455: INFO: model_logger: Epoch 746/1000, train_Loss: 7545.2294921875, val_Loss: 8005.9248]\n",
      "[2024-03-30 21:35:07,653: INFO: model_logger: Epoch 747/1000, train_Loss: 7580.10595703125, val_Loss: 7980.0928]\n",
      "[2024-03-30 21:35:07,856: INFO: model_logger: Epoch 748/1000, train_Loss: 7589.49462890625, val_Loss: 7866.1968]\n",
      "[2024-03-30 21:35:08,112: INFO: model_logger: Epoch 749/1000, train_Loss: 7622.30078125, val_Loss: 7741.9609]\n",
      "[2024-03-30 21:35:08,307: INFO: model_logger: Epoch 750/1000, train_Loss: 7738.5771484375, val_Loss: 7963.4116]\n",
      "[2024-03-30 21:35:08,504: INFO: model_logger: Epoch 751/1000, train_Loss: 7682.83251953125, val_Loss: 7635.0210]\n",
      "[2024-03-30 21:35:08,763: INFO: model_logger: Epoch 752/1000, train_Loss: 7531.412109375, val_Loss: 7678.4170]\n",
      "[2024-03-30 21:35:08,982: INFO: model_logger: Epoch 753/1000, train_Loss: 7495.42333984375, val_Loss: 7615.1357]\n",
      "[2024-03-30 21:35:09,183: INFO: model_logger: Epoch 754/1000, train_Loss: 7681.63720703125, val_Loss: 7743.5391]\n",
      "[2024-03-30 21:35:09,383: INFO: model_logger: Epoch 755/1000, train_Loss: 7535.48193359375, val_Loss: 7606.9233]\n",
      "[2024-03-30 21:35:09,641: INFO: model_logger: Epoch 756/1000, train_Loss: 7561.04296875, val_Loss: 7488.7554]\n",
      "[2024-03-30 21:35:09,836: INFO: model_logger: Epoch 757/1000, train_Loss: 7571.6494140625, val_Loss: 7521.1816]\n",
      "[2024-03-30 21:35:10,039: INFO: model_logger: Epoch 758/1000, train_Loss: 7745.79345703125, val_Loss: 7804.5078]\n",
      "[2024-03-30 21:35:10,296: INFO: model_logger: Epoch 759/1000, train_Loss: 7532.90087890625, val_Loss: 7820.3125]\n",
      "[2024-03-30 21:35:10,494: INFO: model_logger: Epoch 760/1000, train_Loss: 7626.45068359375, val_Loss: 7653.5166]\n",
      "[2024-03-30 21:35:10,689: INFO: model_logger: Epoch 761/1000, train_Loss: 7506.3974609375, val_Loss: 7725.8838]\n",
      "[2024-03-30 21:35:10,948: INFO: model_logger: Epoch 762/1000, train_Loss: 7531.82568359375, val_Loss: 8022.8301]\n",
      "[2024-03-30 21:35:11,153: INFO: model_logger: Epoch 763/1000, train_Loss: 7689.109375, val_Loss: 7904.8828]\n",
      "[2024-03-30 21:35:11,350: INFO: model_logger: Epoch 764/1000, train_Loss: 7545.677734375, val_Loss: 7486.7495]\n",
      "[2024-03-30 21:35:11,610: INFO: model_logger: Epoch 765/1000, train_Loss: 7628.27783203125, val_Loss: 7500.8936]\n",
      "[2024-03-30 21:35:11,809: INFO: model_logger: Epoch 766/1000, train_Loss: 7717.8740234375, val_Loss: 7575.5391]\n",
      "[2024-03-30 21:35:12,007: INFO: model_logger: Epoch 767/1000, train_Loss: 7693.48974609375, val_Loss: 7448.0908]\n",
      "[2024-03-30 21:35:12,204: INFO: model_logger: Epoch 768/1000, train_Loss: 7554.70849609375, val_Loss: 7658.3198]\n",
      "[2024-03-30 21:35:12,462: INFO: model_logger: Epoch 769/1000, train_Loss: 7627.52587890625, val_Loss: 7886.7852]\n",
      "[2024-03-30 21:35:12,660: INFO: model_logger: Epoch 770/1000, train_Loss: 7512.17333984375, val_Loss: 7543.9351]\n",
      "[2024-03-30 21:35:12,857: INFO: model_logger: Epoch 771/1000, train_Loss: 7624.33740234375, val_Loss: 7377.4819]\n",
      "[2024-03-30 21:35:13,112: INFO: model_logger: Epoch 772/1000, train_Loss: 7598.8466796875, val_Loss: 7468.0986]\n",
      "[2024-03-30 21:35:13,310: INFO: model_logger: Epoch 773/1000, train_Loss: 7669.3134765625, val_Loss: 7484.2266]\n",
      "[2024-03-30 21:35:13,508: INFO: model_logger: Epoch 774/1000, train_Loss: 7597.0537109375, val_Loss: 7622.3633]\n",
      "[2024-03-30 21:35:13,800: INFO: model_logger: Epoch 775/1000, train_Loss: 7672.68701171875, val_Loss: 7613.7070]\n",
      "[2024-03-30 21:35:14,012: INFO: model_logger: Epoch 776/1000, train_Loss: 7510.54833984375, val_Loss: 7687.0996]\n",
      "[2024-03-30 21:35:14,222: INFO: model_logger: Epoch 777/1000, train_Loss: 7521.83251953125, val_Loss: 7525.2065]\n",
      "[2024-03-30 21:35:14,422: INFO: model_logger: Epoch 778/1000, train_Loss: 7528.638671875, val_Loss: 7511.6514]\n",
      "[2024-03-30 21:35:14,679: INFO: model_logger: Epoch 779/1000, train_Loss: 7529.16357421875, val_Loss: 7493.0303]\n",
      "[2024-03-30 21:35:14,877: INFO: model_logger: Epoch 780/1000, train_Loss: 7689.88525390625, val_Loss: 7741.9409]\n",
      "[2024-03-30 21:35:15,070: INFO: model_logger: Epoch 781/1000, train_Loss: 7455.8837890625, val_Loss: 7434.1807]\n",
      "[2024-03-30 21:35:15,329: INFO: model_logger: Epoch 782/1000, train_Loss: 7633.6552734375, val_Loss: 7574.8179]\n",
      "[2024-03-30 21:35:15,532: INFO: model_logger: Epoch 783/1000, train_Loss: 7510.8046875, val_Loss: 7756.4004]\n",
      "[2024-03-30 21:35:15,729: INFO: model_logger: Epoch 784/1000, train_Loss: 7508.90380859375, val_Loss: 7358.4233]\n",
      "[2024-03-30 21:35:15,987: INFO: model_logger: Epoch 785/1000, train_Loss: 7586.99951171875, val_Loss: 7737.4995]\n",
      "[2024-03-30 21:35:16,178: INFO: model_logger: Epoch 786/1000, train_Loss: 7501.10888671875, val_Loss: 7376.5576]\n",
      "[2024-03-30 21:35:16,380: INFO: model_logger: Epoch 787/1000, train_Loss: 7435.3623046875, val_Loss: 7399.1436]\n",
      "[2024-03-30 21:35:16,641: INFO: model_logger: Epoch 788/1000, train_Loss: 7552.15380859375, val_Loss: 7547.2568]\n",
      "[2024-03-30 21:35:16,836: INFO: model_logger: Epoch 789/1000, train_Loss: 7696.58984375, val_Loss: 7620.1768]\n",
      "[2024-03-30 21:35:17,030: INFO: model_logger: Epoch 790/1000, train_Loss: 7648.7998046875, val_Loss: 7740.8945]\n",
      "[2024-03-30 21:35:17,223: INFO: model_logger: Epoch 791/1000, train_Loss: 7760.92431640625, val_Loss: 7468.3940]\n",
      "[2024-03-30 21:35:17,486: INFO: model_logger: Epoch 792/1000, train_Loss: 7509.35107421875, val_Loss: 7640.9014]\n",
      "[2024-03-30 21:35:17,687: INFO: model_logger: Epoch 793/1000, train_Loss: 7486.2119140625, val_Loss: 7895.3804]\n",
      "[2024-03-30 21:35:17,885: INFO: model_logger: Epoch 794/1000, train_Loss: 7517.84619140625, val_Loss: 7285.8926]\n",
      "[2024-03-30 21:35:18,137: INFO: model_logger: Epoch 795/1000, train_Loss: 7637.62939453125, val_Loss: 7386.9453]\n",
      "[2024-03-30 21:35:18,333: INFO: model_logger: Epoch 796/1000, train_Loss: 7470.7255859375, val_Loss: 7739.4883]\n",
      "[2024-03-30 21:35:18,539: INFO: model_logger: Epoch 797/1000, train_Loss: 7769.10693359375, val_Loss: 7670.1362]\n",
      "[2024-03-30 21:35:18,799: INFO: model_logger: Epoch 798/1000, train_Loss: 7455.98876953125, val_Loss: 7568.2207]\n",
      "[2024-03-30 21:35:19,018: INFO: model_logger: Epoch 799/1000, train_Loss: 7582.7509765625, val_Loss: 7481.3857]\n",
      "[2024-03-30 21:35:19,224: INFO: model_logger: Epoch 800/1000, train_Loss: 7545.4287109375, val_Loss: 7538.1191]\n",
      "[2024-03-30 21:35:19,420: INFO: model_logger: Epoch 801/1000, train_Loss: 7427.140625, val_Loss: 7848.7788]\n",
      "[2024-03-30 21:35:19,685: INFO: model_logger: Epoch 802/1000, train_Loss: 7476.68701171875, val_Loss: 7920.2202]\n",
      "[2024-03-30 21:35:19,887: INFO: model_logger: Epoch 803/1000, train_Loss: 7498.44287109375, val_Loss: 7211.8984]\n",
      "[2024-03-30 21:35:20,081: INFO: model_logger: Epoch 804/1000, train_Loss: 7573.90625, val_Loss: 7597.3022]\n",
      "[2024-03-30 21:35:20,340: INFO: model_logger: Epoch 805/1000, train_Loss: 7607.86865234375, val_Loss: 7658.2612]\n",
      "[2024-03-30 21:35:20,539: INFO: model_logger: Epoch 806/1000, train_Loss: 7551.73828125, val_Loss: 7579.1230]\n",
      "[2024-03-30 21:35:20,745: INFO: model_logger: Epoch 807/1000, train_Loss: 7492.0263671875, val_Loss: 8121.3584]\n",
      "[2024-03-30 21:35:21,001: INFO: model_logger: Epoch 808/1000, train_Loss: 7500.78076171875, val_Loss: 7660.3535]\n",
      "[2024-03-30 21:35:21,197: INFO: model_logger: Epoch 809/1000, train_Loss: 7587.69482421875, val_Loss: 7415.8984]\n",
      "[2024-03-30 21:35:21,394: INFO: model_logger: Epoch 810/1000, train_Loss: 7487.9130859375, val_Loss: 7404.6729]\n",
      "[2024-03-30 21:35:21,661: INFO: model_logger: Epoch 811/1000, train_Loss: 7705.6640625, val_Loss: 7694.6660]\n",
      "[2024-03-30 21:35:21,859: INFO: model_logger: Epoch 812/1000, train_Loss: 7537.43505859375, val_Loss: 7135.1909]\n",
      "[2024-03-30 21:35:22,057: INFO: model_logger: Epoch 813/1000, train_Loss: 7571.55615234375, val_Loss: 7473.3394]\n",
      "[2024-03-30 21:35:22,251: INFO: model_logger: Epoch 814/1000, train_Loss: 7608.951171875, val_Loss: 7363.2690]\n",
      "[2024-03-30 21:35:22,511: INFO: model_logger: Epoch 815/1000, train_Loss: 7578.1318359375, val_Loss: 7637.9580]\n",
      "[2024-03-30 21:35:22,713: INFO: model_logger: Epoch 816/1000, train_Loss: 7658.1748046875, val_Loss: 7820.1904]\n",
      "[2024-03-30 21:35:22,917: INFO: model_logger: Epoch 817/1000, train_Loss: 7641.3154296875, val_Loss: 7633.3003]\n",
      "[2024-03-30 21:35:23,170: INFO: model_logger: Epoch 818/1000, train_Loss: 7561.22802734375, val_Loss: 7688.0684]\n",
      "[2024-03-30 21:35:23,365: INFO: model_logger: Epoch 819/1000, train_Loss: 7469.6806640625, val_Loss: 7670.1768]\n",
      "[2024-03-30 21:35:23,564: INFO: model_logger: Epoch 820/1000, train_Loss: 7503.86328125, val_Loss: 7539.0156]\n",
      "[2024-03-30 21:35:23,831: INFO: model_logger: Epoch 821/1000, train_Loss: 7533.49658203125, val_Loss: 7679.9624]\n",
      "[2024-03-30 21:35:24,056: INFO: model_logger: Epoch 822/1000, train_Loss: 7409.74609375, val_Loss: 7068.3877]\n",
      "[2024-03-30 21:35:24,266: INFO: model_logger: Epoch 823/1000, train_Loss: 7552.68115234375, val_Loss: 7290.2686]\n",
      "[2024-03-30 21:35:24,459: INFO: model_logger: Epoch 824/1000, train_Loss: 7635.59521484375, val_Loss: 7783.4058]\n",
      "[2024-03-30 21:35:24,718: INFO: model_logger: Epoch 825/1000, train_Loss: 7590.82275390625, val_Loss: 7588.4570]\n",
      "[2024-03-30 21:35:24,921: INFO: model_logger: Epoch 826/1000, train_Loss: 7563.1865234375, val_Loss: 7542.0967]\n",
      "[2024-03-30 21:35:25,116: INFO: model_logger: Epoch 827/1000, train_Loss: 7440.39306640625, val_Loss: 7814.6108]\n",
      "[2024-03-30 21:35:25,369: INFO: model_logger: Epoch 828/1000, train_Loss: 7593.91552734375, val_Loss: 7529.8525]\n",
      "[2024-03-30 21:35:25,569: INFO: model_logger: Epoch 829/1000, train_Loss: 7649.97314453125, val_Loss: 7742.5273]\n",
      "[2024-03-30 21:35:25,768: INFO: model_logger: Epoch 830/1000, train_Loss: 7491.27587890625, val_Loss: 7841.3081]\n",
      "[2024-03-30 21:35:26,031: INFO: model_logger: Epoch 831/1000, train_Loss: 7706.8125, val_Loss: 7504.3262]\n",
      "[2024-03-30 21:35:26,223: INFO: model_logger: Epoch 832/1000, train_Loss: 7539.341796875, val_Loss: 7631.7314]\n",
      "[2024-03-30 21:35:26,418: INFO: model_logger: Epoch 833/1000, train_Loss: 7385.92626953125, val_Loss: 7305.5737]\n",
      "[2024-03-30 21:35:26,676: INFO: model_logger: Epoch 834/1000, train_Loss: 7576.43408203125, val_Loss: 7814.1045]\n",
      "[2024-03-30 21:35:26,875: INFO: model_logger: Epoch 835/1000, train_Loss: 7522.87890625, val_Loss: 7651.6655]\n",
      "[2024-03-30 21:35:27,074: INFO: model_logger: Epoch 836/1000, train_Loss: 7443.57958984375, val_Loss: 7366.8486]\n",
      "[2024-03-30 21:35:27,268: INFO: model_logger: Epoch 837/1000, train_Loss: 7725.37646484375, val_Loss: 7572.5420]\n",
      "[2024-03-30 21:35:27,566: INFO: model_logger: Epoch 838/1000, train_Loss: 7605.23193359375, val_Loss: 7521.6572]\n",
      "[2024-03-30 21:35:27,767: INFO: model_logger: Epoch 839/1000, train_Loss: 7513.68212890625, val_Loss: 7500.0723]\n",
      "[2024-03-30 21:35:27,964: INFO: model_logger: Epoch 840/1000, train_Loss: 7676.171875, val_Loss: 7900.9795]\n",
      "[2024-03-30 21:35:28,232: INFO: model_logger: Epoch 841/1000, train_Loss: 7631.15625, val_Loss: 7820.4858]\n",
      "[2024-03-30 21:35:28,426: INFO: model_logger: Epoch 842/1000, train_Loss: 7460.80908203125, val_Loss: 7310.7852]\n",
      "[2024-03-30 21:35:28,621: INFO: model_logger: Epoch 843/1000, train_Loss: 7502.28271484375, val_Loss: 7390.1558]\n",
      "[2024-03-30 21:35:28,889: INFO: model_logger: Epoch 844/1000, train_Loss: 7485.5380859375, val_Loss: 7521.0518]\n",
      "[2024-03-30 21:35:29,103: INFO: model_logger: Epoch 845/1000, train_Loss: 7616.98095703125, val_Loss: 7536.6108]\n",
      "[2024-03-30 21:35:29,319: INFO: model_logger: Epoch 846/1000, train_Loss: 7496.451171875, val_Loss: 7678.0015]\n",
      "[2024-03-30 21:35:29,516: INFO: model_logger: Epoch 847/1000, train_Loss: 7743.2421875, val_Loss: 7494.3262]\n",
      "[2024-03-30 21:35:29,779: INFO: model_logger: Epoch 848/1000, train_Loss: 7477.78125, val_Loss: 7422.9688]\n",
      "[2024-03-30 21:35:29,973: INFO: model_logger: Epoch 849/1000, train_Loss: 7529.36376953125, val_Loss: 7576.6182]\n",
      "[2024-03-30 21:35:30,170: INFO: model_logger: Epoch 850/1000, train_Loss: 7389.71240234375, val_Loss: 7659.8955]\n",
      "[2024-03-30 21:35:30,429: INFO: model_logger: Epoch 851/1000, train_Loss: 7594.75537109375, val_Loss: 7076.8174]\n",
      "[2024-03-30 21:35:30,624: INFO: model_logger: Epoch 852/1000, train_Loss: 7550.36328125, val_Loss: 7658.7822]\n",
      "[2024-03-30 21:35:30,823: INFO: model_logger: Epoch 853/1000, train_Loss: 7555.2578125, val_Loss: 7518.4819]\n",
      "[2024-03-30 21:35:31,081: INFO: model_logger: Epoch 854/1000, train_Loss: 7657.2578125, val_Loss: 7553.4297]\n",
      "[2024-03-30 21:35:31,279: INFO: model_logger: Epoch 855/1000, train_Loss: 7485.33544921875, val_Loss: 7688.2866]\n",
      "[2024-03-30 21:35:31,481: INFO: model_logger: Epoch 856/1000, train_Loss: 7556.7685546875, val_Loss: 7538.7510]\n",
      "[2024-03-30 21:35:31,738: INFO: model_logger: Epoch 857/1000, train_Loss: 7661.28369140625, val_Loss: 7481.8608]\n",
      "[2024-03-30 21:35:31,937: INFO: model_logger: Epoch 858/1000, train_Loss: 7565.49169921875, val_Loss: 7749.6084]\n",
      "[2024-03-30 21:35:32,140: INFO: model_logger: Epoch 859/1000, train_Loss: 7602.8974609375, val_Loss: 7992.0342]\n",
      "[2024-03-30 21:35:32,334: INFO: model_logger: Epoch 860/1000, train_Loss: 7517.5810546875, val_Loss: 7498.1006]\n",
      "[2024-03-30 21:35:32,597: INFO: model_logger: Epoch 861/1000, train_Loss: 7538.80615234375, val_Loss: 7334.5850]\n",
      "[2024-03-30 21:35:32,792: INFO: model_logger: Epoch 862/1000, train_Loss: 7561.09912109375, val_Loss: 7399.4253]\n",
      "[2024-03-30 21:35:32,986: INFO: model_logger: Epoch 863/1000, train_Loss: 7485.8203125, val_Loss: 7707.1602]\n",
      "[2024-03-30 21:35:33,239: INFO: model_logger: Epoch 864/1000, train_Loss: 7552.69677734375, val_Loss: 7296.3452]\n",
      "[2024-03-30 21:35:33,441: INFO: model_logger: Epoch 865/1000, train_Loss: 7593.94287109375, val_Loss: 7473.7031]\n",
      "[2024-03-30 21:35:33,642: INFO: model_logger: Epoch 866/1000, train_Loss: 7643.0009765625, val_Loss: 7345.2319]\n",
      "[2024-03-30 21:35:33,908: INFO: model_logger: Epoch 867/1000, train_Loss: 7576.46484375, val_Loss: 7620.7480]\n",
      "[2024-03-30 21:35:34,117: INFO: model_logger: Epoch 868/1000, train_Loss: 7585.57568359375, val_Loss: 7897.4883]\n",
      "[2024-03-30 21:35:34,317: INFO: model_logger: Epoch 869/1000, train_Loss: 7601.26708984375, val_Loss: 7783.0703]\n",
      "[2024-03-30 21:35:34,517: INFO: model_logger: Epoch 870/1000, train_Loss: 7552.2998046875, val_Loss: 7578.8594]\n",
      "[2024-03-30 21:35:34,783: INFO: model_logger: Epoch 871/1000, train_Loss: 7515.4443359375, val_Loss: 7663.9819]\n",
      "[2024-03-30 21:35:34,976: INFO: model_logger: Epoch 872/1000, train_Loss: 7659.25244140625, val_Loss: 7898.4233]\n",
      "[2024-03-30 21:35:35,168: INFO: model_logger: Epoch 873/1000, train_Loss: 7497.365234375, val_Loss: 7650.6279]\n",
      "[2024-03-30 21:35:35,426: INFO: model_logger: Epoch 874/1000, train_Loss: 7403.41015625, val_Loss: 7400.2256]\n",
      "[2024-03-30 21:35:35,633: INFO: model_logger: Epoch 875/1000, train_Loss: 7679.70263671875, val_Loss: 7674.0752]\n",
      "[2024-03-30 21:35:35,831: INFO: model_logger: Epoch 876/1000, train_Loss: 7467.9326171875, val_Loss: 7602.5073]\n",
      "[2024-03-30 21:35:36,095: INFO: model_logger: Epoch 877/1000, train_Loss: 7615.375, val_Loss: 7729.1460]\n",
      "[2024-03-30 21:35:36,292: INFO: model_logger: Epoch 878/1000, train_Loss: 7526.8671875, val_Loss: 7544.8711]\n",
      "[2024-03-30 21:35:36,492: INFO: model_logger: Epoch 879/1000, train_Loss: 7623.951171875, val_Loss: 7605.2412]\n",
      "[2024-03-30 21:35:36,762: INFO: model_logger: Epoch 880/1000, train_Loss: 7560.65771484375, val_Loss: 7449.8242]\n",
      "[2024-03-30 21:35:36,962: INFO: model_logger: Epoch 881/1000, train_Loss: 7559.21044921875, val_Loss: 7682.7241]\n",
      "[2024-03-30 21:35:37,157: INFO: model_logger: Epoch 882/1000, train_Loss: 7657.00732421875, val_Loss: 7927.7188]\n",
      "[2024-03-30 21:35:37,352: INFO: model_logger: Epoch 883/1000, train_Loss: 7483.12109375, val_Loss: 7563.1602]\n",
      "[2024-03-30 21:35:37,653: INFO: model_logger: Epoch 884/1000, train_Loss: 7637.046875, val_Loss: 7592.2539]\n",
      "[2024-03-30 21:35:37,860: INFO: model_logger: Epoch 885/1000, train_Loss: 7688.18115234375, val_Loss: 7643.2632]\n",
      "[2024-03-30 21:35:38,055: INFO: model_logger: Epoch 886/1000, train_Loss: 7645.802734375, val_Loss: 7327.2202]\n",
      "[2024-03-30 21:35:38,310: INFO: model_logger: Epoch 887/1000, train_Loss: 7601.13232421875, val_Loss: 7651.8057]\n",
      "[2024-03-30 21:35:38,508: INFO: model_logger: Epoch 888/1000, train_Loss: 7807.05126953125, val_Loss: 7648.2827]\n",
      "[2024-03-30 21:35:38,707: INFO: model_logger: Epoch 889/1000, train_Loss: 7616.3447265625, val_Loss: 7540.0679]\n",
      "[2024-03-30 21:35:38,984: INFO: model_logger: Epoch 890/1000, train_Loss: 7546.27001953125, val_Loss: 7707.0801]\n",
      "[2024-03-30 21:35:39,189: INFO: model_logger: Epoch 891/1000, train_Loss: 7536.0888671875, val_Loss: 7469.0293]\n",
      "[2024-03-30 21:35:39,394: INFO: model_logger: Epoch 892/1000, train_Loss: 7612.90771484375, val_Loss: 7452.7432]\n",
      "[2024-03-30 21:35:39,594: INFO: model_logger: Epoch 893/1000, train_Loss: 7479.646484375, val_Loss: 7605.5874]\n",
      "[2024-03-30 21:35:39,857: INFO: model_logger: Epoch 894/1000, train_Loss: 7647.013671875, val_Loss: 7662.0522]\n",
      "[2024-03-30 21:35:40,070: INFO: model_logger: Epoch 895/1000, train_Loss: 7503.2041015625, val_Loss: 7768.0308]\n",
      "[2024-03-30 21:35:40,270: INFO: model_logger: Epoch 896/1000, train_Loss: 7656.20556640625, val_Loss: 7596.2783]\n",
      "[2024-03-30 21:35:40,530: INFO: model_logger: Epoch 897/1000, train_Loss: 7482.79931640625, val_Loss: 8050.0718]\n",
      "[2024-03-30 21:35:40,731: INFO: model_logger: Epoch 898/1000, train_Loss: 7580.623046875, val_Loss: 7403.1694]\n",
      "[2024-03-30 21:35:40,930: INFO: model_logger: Epoch 899/1000, train_Loss: 7600.703125, val_Loss: 7708.6855]\n",
      "[2024-03-30 21:35:41,189: INFO: model_logger: Epoch 900/1000, train_Loss: 7477.75, val_Loss: 7872.1577]\n",
      "[2024-03-30 21:35:41,383: INFO: model_logger: Epoch 901/1000, train_Loss: 7503.9931640625, val_Loss: 7653.6318]\n",
      "[2024-03-30 21:35:41,578: INFO: model_logger: Epoch 902/1000, train_Loss: 7618.79296875, val_Loss: 7237.7314]\n",
      "[2024-03-30 21:35:41,837: INFO: model_logger: Epoch 903/1000, train_Loss: 7635.8271484375, val_Loss: 7552.3936]\n",
      "[2024-03-30 21:35:42,040: INFO: model_logger: Epoch 904/1000, train_Loss: 7685.70703125, val_Loss: 7884.3296]\n",
      "[2024-03-30 21:35:42,243: INFO: model_logger: Epoch 905/1000, train_Loss: 7496.4609375, val_Loss: 7654.0703]\n",
      "[2024-03-30 21:35:42,436: INFO: model_logger: Epoch 906/1000, train_Loss: 7607.08984375, val_Loss: 7788.0039]\n",
      "[2024-03-30 21:35:42,696: INFO: model_logger: Epoch 907/1000, train_Loss: 7538.30615234375, val_Loss: 7760.0498]\n",
      "[2024-03-30 21:35:42,898: INFO: model_logger: Epoch 908/1000, train_Loss: 7591.11376953125, val_Loss: 7497.3672]\n",
      "[2024-03-30 21:35:43,114: INFO: model_logger: Epoch 909/1000, train_Loss: 7559.0166015625, val_Loss: 7674.2710]\n",
      "[2024-03-30 21:35:43,376: INFO: model_logger: Epoch 910/1000, train_Loss: 7503.0947265625, val_Loss: 7507.3398]\n",
      "[2024-03-30 21:35:43,572: INFO: model_logger: Epoch 911/1000, train_Loss: 7459.42626953125, val_Loss: 7548.2046]\n",
      "[2024-03-30 21:35:43,770: INFO: model_logger: Epoch 912/1000, train_Loss: 7451.42578125, val_Loss: 7932.2026]\n",
      "[2024-03-30 21:35:44,051: INFO: model_logger: Epoch 913/1000, train_Loss: 7435.552734375, val_Loss: 7527.5303]\n",
      "[2024-03-30 21:35:44,269: INFO: model_logger: Epoch 914/1000, train_Loss: 7518.7763671875, val_Loss: 7661.0537]\n",
      "[2024-03-30 21:35:44,462: INFO: model_logger: Epoch 915/1000, train_Loss: 7500.9306640625, val_Loss: 7872.7959]\n",
      "[2024-03-30 21:35:44,658: INFO: model_logger: Epoch 916/1000, train_Loss: 7491.96484375, val_Loss: 7604.2129]\n",
      "[2024-03-30 21:35:44,928: INFO: model_logger: Epoch 917/1000, train_Loss: 7687.7958984375, val_Loss: 7706.7480]\n",
      "[2024-03-30 21:35:45,134: INFO: model_logger: Epoch 918/1000, train_Loss: 7523.09619140625, val_Loss: 7504.2266]\n",
      "[2024-03-30 21:35:45,328: INFO: model_logger: Epoch 919/1000, train_Loss: 7536.2822265625, val_Loss: 7757.4780]\n",
      "[2024-03-30 21:35:45,589: INFO: model_logger: Epoch 920/1000, train_Loss: 7473.4873046875, val_Loss: 7527.2319]\n",
      "[2024-03-30 21:35:45,790: INFO: model_logger: Epoch 921/1000, train_Loss: 7610.16357421875, val_Loss: 7434.5117]\n",
      "[2024-03-30 21:35:45,986: INFO: model_logger: Epoch 922/1000, train_Loss: 7556.779296875, val_Loss: 7467.5742]\n",
      "[2024-03-30 21:35:46,242: INFO: model_logger: Epoch 923/1000, train_Loss: 7478.37451171875, val_Loss: 7681.4814]\n",
      "[2024-03-30 21:35:46,446: INFO: model_logger: Epoch 924/1000, train_Loss: 7394.72900390625, val_Loss: 7748.5381]\n",
      "[2024-03-30 21:35:46,643: INFO: model_logger: Epoch 925/1000, train_Loss: 7616.2880859375, val_Loss: 7330.5537]\n",
      "[2024-03-30 21:35:46,906: INFO: model_logger: Epoch 926/1000, train_Loss: 7591.693359375, val_Loss: 7361.2598]\n",
      "[2024-03-30 21:35:47,100: INFO: model_logger: Epoch 927/1000, train_Loss: 7372.00732421875, val_Loss: 7069.3506]\n",
      "[2024-03-30 21:35:47,295: INFO: model_logger: Epoch 928/1000, train_Loss: 7585.49169921875, val_Loss: 7516.8682]\n",
      "[2024-03-30 21:35:47,495: INFO: model_logger: Epoch 929/1000, train_Loss: 7520.1982421875, val_Loss: 7407.5503]\n",
      "[2024-03-30 21:35:47,787: INFO: model_logger: Epoch 930/1000, train_Loss: 7558.62646484375, val_Loss: 7531.2148]\n",
      "[2024-03-30 21:35:48,021: INFO: model_logger: Epoch 931/1000, train_Loss: 7575.5615234375, val_Loss: 7504.5581]\n",
      "[2024-03-30 21:35:48,240: INFO: model_logger: Epoch 932/1000, train_Loss: 7633.05712890625, val_Loss: 7636.4819]\n",
      "[2024-03-30 21:35:48,550: INFO: model_logger: Epoch 933/1000, train_Loss: 7493.71240234375, val_Loss: 7664.7188]\n",
      "[2024-03-30 21:35:48,783: INFO: model_logger: Epoch 934/1000, train_Loss: 7444.50927734375, val_Loss: 7456.8140]\n",
      "[2024-03-30 21:35:49,005: INFO: model_logger: Epoch 935/1000, train_Loss: 7626.45068359375, val_Loss: 7631.2007]\n",
      "[2024-03-30 21:35:49,288: INFO: model_logger: Epoch 936/1000, train_Loss: 7531.97900390625, val_Loss: 7623.4131]\n",
      "[2024-03-30 21:35:49,487: INFO: model_logger: Epoch 937/1000, train_Loss: 7547.41796875, val_Loss: 7554.7324]\n",
      "[2024-03-30 21:35:49,697: INFO: model_logger: Epoch 938/1000, train_Loss: 7483.0771484375, val_Loss: 7517.3242]\n",
      "[2024-03-30 21:35:49,895: INFO: model_logger: Epoch 939/1000, train_Loss: 7532.896484375, val_Loss: 7316.8555]\n",
      "[2024-03-30 21:35:50,155: INFO: model_logger: Epoch 940/1000, train_Loss: 7500.90625, val_Loss: 7603.7646]\n",
      "[2024-03-30 21:35:50,350: INFO: model_logger: Epoch 941/1000, train_Loss: 7567.93115234375, val_Loss: 8033.9297]\n",
      "[2024-03-30 21:35:50,553: INFO: model_logger: Epoch 942/1000, train_Loss: 7446.60595703125, val_Loss: 7587.0947]\n",
      "[2024-03-30 21:35:50,827: INFO: model_logger: Epoch 943/1000, train_Loss: 7500.6015625, val_Loss: 7581.7397]\n",
      "[2024-03-30 21:35:51,023: INFO: model_logger: Epoch 944/1000, train_Loss: 7562.22119140625, val_Loss: 7368.2939]\n",
      "[2024-03-30 21:35:51,216: INFO: model_logger: Epoch 945/1000, train_Loss: 7646.8505859375, val_Loss: 7688.7471]\n",
      "[2024-03-30 21:35:51,471: INFO: model_logger: Epoch 946/1000, train_Loss: 7446.8916015625, val_Loss: 7764.6006]\n",
      "[2024-03-30 21:35:51,678: INFO: model_logger: Epoch 947/1000, train_Loss: 7656.4443359375, val_Loss: 7614.9248]\n",
      "[2024-03-30 21:35:51,876: INFO: model_logger: Epoch 948/1000, train_Loss: 7425.45751953125, val_Loss: 7694.5054]\n",
      "[2024-03-30 21:35:52,135: INFO: model_logger: Epoch 949/1000, train_Loss: 7556.7744140625, val_Loss: 7847.9600]\n",
      "[2024-03-30 21:35:52,328: INFO: model_logger: Epoch 950/1000, train_Loss: 7603.77294921875, val_Loss: 7405.5171]\n",
      "[2024-03-30 21:35:52,526: INFO: model_logger: Epoch 951/1000, train_Loss: 7441.3369140625, val_Loss: 7299.7148]\n",
      "[2024-03-30 21:35:52,766: INFO: model_logger: Epoch 952/1000, train_Loss: 7637.076171875, val_Loss: 7605.7734]\n",
      "[2024-03-30 21:35:53,093: INFO: model_logger: Epoch 953/1000, train_Loss: 7581.9794921875, val_Loss: 7675.2334]\n",
      "[2024-03-30 21:35:53,313: INFO: model_logger: Epoch 954/1000, train_Loss: 7571.4384765625, val_Loss: 7623.2007]\n",
      "[2024-03-30 21:35:53,541: INFO: model_logger: Epoch 955/1000, train_Loss: 7516.35107421875, val_Loss: 7826.9746]\n",
      "[2024-03-30 21:35:53,816: INFO: model_logger: Epoch 956/1000, train_Loss: 7466.15625, val_Loss: 7721.5811]\n",
      "[2024-03-30 21:35:54,041: INFO: model_logger: Epoch 957/1000, train_Loss: 7553.55615234375, val_Loss: 7745.4150]\n",
      "[2024-03-30 21:35:54,279: INFO: model_logger: Epoch 958/1000, train_Loss: 7566.71337890625, val_Loss: 7464.7627]\n",
      "[2024-03-30 21:35:54,564: INFO: model_logger: Epoch 959/1000, train_Loss: 7560.6025390625, val_Loss: 7425.1885]\n",
      "[2024-03-30 21:35:54,869: INFO: model_logger: Epoch 960/1000, train_Loss: 7532.7646484375, val_Loss: 7686.5547]\n",
      "[2024-03-30 21:35:55,087: INFO: model_logger: Epoch 961/1000, train_Loss: 7443.248046875, val_Loss: 7542.1206]\n",
      "[2024-03-30 21:35:55,307: INFO: model_logger: Epoch 962/1000, train_Loss: 7586.7509765625, val_Loss: 7590.6909]\n",
      "[2024-03-30 21:35:55,592: INFO: model_logger: Epoch 963/1000, train_Loss: 7381.77001953125, val_Loss: 7518.2793]\n",
      "[2024-03-30 21:35:55,800: INFO: model_logger: Epoch 964/1000, train_Loss: 7571.75439453125, val_Loss: 7898.1826]\n",
      "[2024-03-30 21:35:56,020: INFO: model_logger: Epoch 965/1000, train_Loss: 7404.935546875, val_Loss: 7726.0400]\n",
      "[2024-03-30 21:35:56,301: INFO: model_logger: Epoch 966/1000, train_Loss: 7586.5703125, val_Loss: 7760.1401]\n",
      "[2024-03-30 21:35:56,509: INFO: model_logger: Epoch 967/1000, train_Loss: 7509.91796875, val_Loss: 7761.7319]\n",
      "[2024-03-30 21:35:56,745: INFO: model_logger: Epoch 968/1000, train_Loss: 7491.50244140625, val_Loss: 7972.9565]\n",
      "[2024-03-30 21:35:57,068: INFO: model_logger: Epoch 969/1000, train_Loss: 7501.03369140625, val_Loss: 7745.5229]\n",
      "[2024-03-30 21:35:57,345: INFO: model_logger: Epoch 970/1000, train_Loss: 7614.5166015625, val_Loss: 7688.7568]\n",
      "[2024-03-30 21:35:57,567: INFO: model_logger: Epoch 971/1000, train_Loss: 7615.28564453125, val_Loss: 7701.0518]\n",
      "[2024-03-30 21:35:57,847: INFO: model_logger: Epoch 972/1000, train_Loss: 7492.33984375, val_Loss: 7429.2822]\n",
      "[2024-03-30 21:35:58,065: INFO: model_logger: Epoch 973/1000, train_Loss: 7597.646484375, val_Loss: 7818.7451]\n",
      "[2024-03-30 21:35:58,288: INFO: model_logger: Epoch 974/1000, train_Loss: 7654.2275390625, val_Loss: 7652.9648]\n",
      "[2024-03-30 21:35:58,487: INFO: model_logger: Epoch 975/1000, train_Loss: 7628.12109375, val_Loss: 7454.4570]\n",
      "[2024-03-30 21:35:58,780: INFO: model_logger: Epoch 976/1000, train_Loss: 7561.85888671875, val_Loss: 7846.2119]\n",
      "[2024-03-30 21:35:59,013: INFO: model_logger: Epoch 977/1000, train_Loss: 7640.296875, val_Loss: 7606.0225]\n",
      "[2024-03-30 21:35:59,233: INFO: model_logger: Epoch 978/1000, train_Loss: 7579.08837890625, val_Loss: 7574.3721]\n",
      "[2024-03-30 21:35:59,505: INFO: model_logger: Epoch 979/1000, train_Loss: 7448.49365234375, val_Loss: 7719.4482]\n",
      "[2024-03-30 21:35:59,711: INFO: model_logger: Epoch 980/1000, train_Loss: 7535.09130859375, val_Loss: 7860.4404]\n",
      "[2024-03-30 21:35:59,915: INFO: model_logger: Epoch 981/1000, train_Loss: 7528.6708984375, val_Loss: 7710.0020]\n",
      "[2024-03-30 21:36:00,199: INFO: model_logger: Epoch 982/1000, train_Loss: 7594.47412109375, val_Loss: 7763.9902]\n",
      "[2024-03-30 21:36:00,434: INFO: model_logger: Epoch 983/1000, train_Loss: 7624.1181640625, val_Loss: 7683.9004]\n",
      "[2024-03-30 21:36:00,681: INFO: model_logger: Epoch 984/1000, train_Loss: 7513.1865234375, val_Loss: 7652.5342]\n",
      "[2024-03-30 21:36:00,904: INFO: model_logger: Epoch 985/1000, train_Loss: 7539.9599609375, val_Loss: 7695.2676]\n",
      "[2024-03-30 21:36:01,237: INFO: model_logger: Epoch 986/1000, train_Loss: 7468.9521484375, val_Loss: 7701.7061]\n",
      "[2024-03-30 21:36:01,447: INFO: model_logger: Epoch 987/1000, train_Loss: 7509.9013671875, val_Loss: 7645.7803]\n",
      "[2024-03-30 21:36:01,658: INFO: model_logger: Epoch 988/1000, train_Loss: 7526.31005859375, val_Loss: 7540.3706]\n",
      "[2024-03-30 21:36:01,965: INFO: model_logger: Epoch 989/1000, train_Loss: 7582.0087890625, val_Loss: 7758.0464]\n",
      "[2024-03-30 21:36:02,316: INFO: model_logger: Epoch 990/1000, train_Loss: 7433.18505859375, val_Loss: 7707.4902]\n",
      "[2024-03-30 21:36:02,593: INFO: model_logger: Epoch 991/1000, train_Loss: 7569.09521484375, val_Loss: 7829.3672]\n",
      "[2024-03-30 21:36:02,899: INFO: model_logger: Epoch 992/1000, train_Loss: 7365.1650390625, val_Loss: 7551.6094]\n",
      "[2024-03-30 21:36:03,127: INFO: model_logger: Epoch 993/1000, train_Loss: 7409.02099609375, val_Loss: 7787.9092]\n",
      "[2024-03-30 21:36:03,343: INFO: model_logger: Epoch 994/1000, train_Loss: 7508.3935546875, val_Loss: 7633.5718]\n",
      "[2024-03-30 21:36:03,645: INFO: model_logger: Epoch 995/1000, train_Loss: 7628.0341796875, val_Loss: 7571.6221]\n",
      "[2024-03-30 21:36:03,954: INFO: model_logger: Epoch 996/1000, train_Loss: 7617.208984375, val_Loss: 7569.0225]\n",
      "[2024-03-30 21:36:04,168: INFO: model_logger: Epoch 997/1000, train_Loss: 7563.5, val_Loss: 7504.0811]\n",
      "[2024-03-30 21:36:04,372: INFO: model_logger: Epoch 998/1000, train_Loss: 7556.47119140625, val_Loss: 7980.8018]\n",
      "[2024-03-30 21:36:04,648: INFO: model_logger: Epoch 999/1000, train_Loss: 7607.521484375, val_Loss: 7808.4194]\n",
      "[2024-03-30 21:36:04,864: INFO: model_logger: Epoch 1000/1000, train_Loss: 7627.271484375, val_Loss: 7739.3203]\n"
     ]
    }
   ],
   "source": [
    "# Model Trainer training pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
